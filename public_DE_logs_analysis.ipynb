{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8ec4d62",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<style>\n",
    "    \n",
    "</style>\n",
    "*Оглавление создал вручную с помощью Markdown и HTML. Подход не лучший, но по крайней мере рабочий, а оглавление будет работать даже если у пользователя нет Nbextensions toc/2main*</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be07bf5f",
   "metadata": {},
   "source": [
    "## TOC:\n",
    "* **[Постановка задачи.](#1)**  \n",
    "    * [Предисловие.](#1.1)  \n",
    "\n",
    "* **[Ход работы.](#2)**  \n",
    "    * [Структура проекта.](#2.1)  \n",
    "\n",
    "* **[Загрузка и анализ данных источика.](#3)**  \n",
    "    * [Импорты, установка компонентов для работы.](#3.1)  \n",
    "\n",
    "* **[Extract.](#4)**  \n",
    "    * [Извлечение признаков.](#4.1)  \n",
    "    * [Сведение полученных признаков.](#4.2)  \n",
    "    * [Сохранение датафрейма.](#4.3)  \n",
    "\n",
    "* **[Transform.](#5)**  \n",
    "    * [Решение в *Pandas.*](#5.1)  \n",
    "        * [Задания 1-4](#5.1.1)  \n",
    "        * [Задания 5-6](#5.1.2)  \n",
    "        * [Задание 7](#5.1.3)  \n",
    "        * [Задания 8-9](#5.1.4)  \n",
    "\n",
    "    * [Решение в *SPARK.*](#5.2)  \n",
    "        * [*SPARK.* Задания 1-4](#5.3)  \n",
    "        * [*SPARK.* Задания 5-6](#5.4)  \n",
    "        * [*SPARK.* Задание 7](#5.5)  \n",
    "        * [*SPARK.* Задания 8-9](#5.6)  \n",
    "\n",
    "* **[Load.](#6)**  \n",
    "    * [Работа с базами данных.](#6.1)  \n",
    "\n",
    "* **[Вывод.](#7)**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e2bcdf",
   "metadata": {},
   "source": [
    "# <center>Анализ логов web-сайта</center>\n",
    "\n",
    "<p style=\"text-align:right;\">выполнил: Морозов Е.А.</p>\n",
    "\n",
    "***\n",
    "\n",
    "## 1. Постановка задачи. <a class=\"anchor\" id=\"1\"></a>\n",
    "\n",
    "Необходимо осуществить анализ логов, создав скрипт для формирования витрины на основе логов web-сайта. Разработаный скрипт витрины данных должен иметь следующее содержание и отображать следующие данные: \n",
    "\n",
    "1. Суррогатный ключ устройства.\n",
    "2. Название устройства.\n",
    "3. Количество пользователей.\n",
    "4. Доля пользователей данного устройства от общего числа пользователей.\n",
    "5. Количество совершенных действий для данного устройства.\n",
    "6. Доля совершенных действий с данного устройства, относительно других устройств.\n",
    "7. Список из 5 самых популярных браузеров, используемых на данном устройстве различными пользователями, с указанием доли использования для данного браузера относительно остальных браузеров.\n",
    "8. Количество ответов сервера, отличных от 200, на данном устройстве.\n",
    "9. Для каждого из ответов сервера, отличных от 200, сформировать поле, в котором будет содержаться количество ответов данного типа.\n",
    "\n",
    "Источник данных (логи web-сайта): https://disk.yandex.ru/d/обезличено  \n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "### Предисловие.  <a class=\"anchor\" id=\"1.1\"></a>  \n",
    "\n",
    "Будучи новичком в области инженерии данных, я всё ещё мало знаком с лучшими или стандартными приёмами работы над подобным заданием и в данной работе вся последовательность рабочих процессов выстраивалась самостоятельно и по наитию. Целью было попробовать применить наиболее заинтересовавшие инструменты и технологии.  \n",
    "\n",
    "Задача, несмотря на кажущуюся банальность, заинтересовала именно возможнностью осуществить обработку ощутитмого объёма данных более или менее эффективным способом. На последнем месте работы именно отсутствие подобной возможности меня особенно удручало. В своё время, по неизвестной причине, было решено передавать данные и документировать рабочие процессы, используя \"мощь\" Microsoft Office Excel с макросами на VBA... Без шуток абсолютно всё, кроме бухгалтерской информации: от базы данных продукции и отгрузок, до сводной таблицы с информацией о закрытых проектах - всё находилось в нескольких перегруженных таблицах, для имитации общего доступа хранившихся на сервере. Каждый год файлы копировались и переименовывался в соотв. номер, но только предтавьте как всё это хоязйство \"работало\" уже в конце первого-второго месяца каждого года. \n",
    "\n",
    "Я ещё с детства (серьезно) полюбил табличные процессоры, но такая привязанность даже у меня вызвала неподдельное удивление, затем сменившийся катастрофическим разочарованием. Это было не просто бутылочное горлышко в рабочих процессах, а настоящая боль. Опыт работы дал понять, что поменять устоявшуюся архаичную модель не получится, поскольку были интересанты её функционирования. В конце концов рабочие отношения были расторгнуты, а для \"закрытия гештальта\" стало банально интересно сформировать понимание, из чего и как может быть построен правильный процесс работы с данными, особенно объёмными. Поэтому задача видится интересной именно в ретроспективе.  \n",
    "\n",
    "***\n",
    "\n",
    "## 2. Ход работы. <a class=\"anchor\" id=\"2\"></a>\n",
    "\n",
    "В рамках учебной работы кажется логичным разбить выполнение на стадии в рамках **ETL**-процесса (в понимании автора): *extract*, *transform* и *load*.\n",
    "\n",
    "- Загрузим и проанализируем данные.  \n",
    "\n",
    "\n",
    "- На стадии **извлечения** данных обработаем файл логов с помощью регулярных выражений и методов работы со строками языка программирования ***python***. Это будет самый \"нижний\" слой обработки.  \n",
    "\n",
    "\n",
    "- Сведём данные в пригодную для дальнейшей обработки форму - табличную, используя соотв. библиотеки (вероятнее всего не в Базы Данных, чтобы избежать проектирования и сопутствующих процессов, а в датафреймы **Pandas**/**Dusk**/**SPARK**).  \n",
    "\n",
    "\n",
    "- На стадии **преобразования** ответим на вопросы задания, группируя и сортируя данные подходящим способом и выбрав нужные инструменты и, возможно, сравнив различные подходы (вероятнее всего **Pandas**, **Spark** и **SQL-запросы**).  \n",
    "\n",
    "\n",
    "- На стадии **выгрузки** сформируем и сохраним полученную в результате работы скрипта витрину.  \n",
    "\n",
    "\n",
    "- Составим вывод об эффективности процесса.\n",
    "\n",
    "\n",
    "### 2.1. Структура проекта. <a class=\"anchor\" id=\"2.1\"></a>\n",
    "\n",
    "Ниже приводятся пояснения к файловой структуре проекта:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "413cc8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В рабочей директории создана папка 'morozov_ea' для организации хранения данных проекта.\n",
      "\n",
      "total 48K\r\n",
      "drwxr-x---  9 jupyter-morozov_evgeny jupyter-morozov_evgeny 4.0K Dec 22 18:33 .\r\n",
      "drwxr-xr-x 31 root                   root                   4.0K Dec 29 14:51 ..\r\n",
      "-rw-r--r--  1 jupyter-morozov_evgeny jupyter-morozov_evgeny  220 Feb 25  2020 .bash_logout\r\n",
      "-rw-r--r--  1 jupyter-morozov_evgeny jupyter-morozov_evgeny 3.7K Feb 25  2020 .bashrc\r\n",
      "drwxr-xr-x  5 jupyter-morozov_evgeny jupyter-morozov_evgeny 4.0K Dec 22 18:34 .cache\r\n",
      "drwxrwsr-x  3 jupyter-morozov_evgeny jupyter-morozov_evgeny 4.0K Dec 22 18:33 .conda\r\n",
      "lrwxrwxrwx  1 jupyter-morozov_evgeny jupyter-morozov_evgeny   55 Dec 16 11:34 dags -> /root/data-analysis/airflow/dags/jupyter-morozov_evgeny\r\n",
      "drwxr-xr-x  2 jupyter-morozov_evgeny jupyter-morozov_evgeny 4.0K Dec 16 22:19 .ipynb_checkpoints\r\n",
      "drwxr-xr-x  3 jupyter-morozov_evgeny jupyter-morozov_evgeny 4.0K Dec 16 22:25 .ipython\r\n",
      "drwxr-xr-x  3 jupyter-morozov_evgeny jupyter-morozov_evgeny 4.0K Dec 21 21:52 .jupyter\r\n",
      "drwxr-xr-x  6 jupyter-morozov_evgeny jupyter-morozov_evgeny 4.0K Dec 22 18:34 .local\r\n",
      "drwxr-xr-x  6 jupyter-morozov_evgeny jupyter-morozov_evgeny 4.0K Jan  9 00:12 morozov_ea\r\n",
      "-rw-r--r--  1 jupyter-morozov_evgeny jupyter-morozov_evgeny  807 Feb 25  2020 .profile\r\n"
     ]
    }
   ],
   "source": [
    "# в рабочей директории создана папка для организации хранения данных проекта\n",
    "print(\"В рабочей директории создана папка 'morozov_ea' для организации хранения данных проекта.\\n\")\n",
    "! ls -lah .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c189655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Папка проекта содержит:\n",
      " - папку \u001b[1m'input_data'\u001b[0m с исходными данными задания,\n",
      " - папку \u001b[1m'output_data'\u001b[0m с файлами, получаемыми в ходе работы и считающимися итоговыми результатами,\n",
      " - папку \u001b[1m'spark-warehouse'\u001b[0m , создаваемую при работе фреймворка SPARK (подробнее в соотв. разделе исследования).\n",
      "\n",
      "total 264K\r\n",
      "drwxr-xr-x 3 jupyter-morozov_evgeny jupyter-morozov_evgeny 4.0K Jan  7 23:10 input_data\r\n",
      "-rw-r--r-- 1 jupyter-morozov_evgeny jupyter-morozov_evgeny 251K Jan  9 00:12 morozov_ea_final_03.ipynb\r\n",
      "drwxr-xr-x 5 jupyter-morozov_evgeny jupyter-morozov_evgeny 4.0K Jan  8 23:06 output_data\r\n",
      "drwxr-xr-x 3 jupyter-morozov_evgeny jupyter-morozov_evgeny 4.0K Jan  9 00:18 spark-warehouse\r\n"
     ]
    }
   ],
   "source": [
    "# структура проекта и файлы\n",
    "print(\"Папка проекта содержит:\\n - папку\",\n",
    "      \"\\033[1m\" + \"'input_data'\" + \"\\033[0m\",\n",
    "      \"с исходными данными задания,\\n - папку\",\n",
    "      \"\\033[1m\" + \"'output_data'\" + \"\\033[0m\",\n",
    "      \"с файлами, получаемыми в ходе работы и считающимися итоговыми результатами,\\n - папку\",\n",
    "      \"\\033[1m\" + \"'spark-warehouse'\" + \"\\033[0m\",\n",
    "      \", создаваемую при работе фреймворка SPARK (подробнее в соотв. разделе исследования).\\n\")\n",
    "!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46b25175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "рабочие файлы в 'input_data':\n",
      "total 3.4G\r\n",
      "-rw-r--r-- 1 jupyter-morozov_evgeny jupyter-morozov_evgeny 3.3G Jan  7 23:07 access-Copy1.log\r\n",
      "-rw-r--r-- 1 jupyter-morozov_evgeny jupyter-morozov_evgeny  64M Jan  7 23:07 access-Copy1_short.log\r\n",
      "-rw-r--r-- 1 jupyter-morozov_evgeny jupyter-morozov_evgeny  13M Dec 17 14:05 client_hostname.csv\r\n"
     ]
    }
   ],
   "source": [
    "print(\"рабочие файлы в 'input_data':\")\n",
    "! ls -lh ./input_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791de89a",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## 3. Загрузка и анализ данных источика. <a class=\"anchor\" id=\"3\"></a>\n",
    "\n",
    "После пояснения структуры проекта, начнём исследование.  В соответствии с заголовком загрузим и проанализируем данные в \"сыром\" виде.\n",
    "\n",
    "### Импорты, установка компонентов для работы. <a class=\"anchor\" id=\"3.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9823a853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеки:\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import sample\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e32cda74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "# импорты модулей Spark:\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "import pyspark.pandas as ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c6f1c8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<style>\n",
    "    \n",
    "</style>\n",
    "<b>комментарий:</b>\n",
    "<br>\n",
    "валилось много варнингов `\"WARNING:root:'PYARROW_IGNORE_TIMEZONE'\"`, с которыми разбираться было некогда, вдобавок **os.environ** итак указывал `'PYARROW_IGNORE_TIMEZONE':'l'`, по итогу со стандартным поведением всё работало адекватно.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cf1def6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество строк в файле логов = 10 365 152 \n",
      "\n",
      "Образец данных:\n",
      "\n",
      "5.210.199.221 - - [26/Jan/2019:19:58:43 +0330] \"GET /m/filter/p62%2Cstexists HTTP/1.1\" 200 19441 \"https://www-zanbil-ir.cdn.ampproject.org/v/s/www.zanbil.ir/m?amp_js_v=0.1&usqp=mq331AQECAEoAQ%3D%3D\" \"Mozilla/5.0 (Linux; Android 6.0.1; SAMSUNG SM-J700H Build/MMB29K) AppleWebKit/537.36 (KHTML, like Gecko) SamsungBrowser/7.4 Chrome/59.0.3071.125 Mobile Safari/537.36\" \"-\"\n",
      "\n",
      "5.127.49.29 - - [22/Jan/2019:16:19:52 +0330] \"GET /image/43688/productModel/200x200 HTTP/1.1\" 200 4662 \"https://www.zanbil.ir/m/filter/p49?page=1\" \"Mozilla/5.0 (Linux; Android 5.1.1; SAMSUNG SM-J320F Build/LMY47V) AppleWebKit/537.36 (KHTML, like Gecko) SamsungBrowser/7.4 Chrome/59.0.3071.125 Mobile Safari/537.36\" \"-\"\n",
      "\n",
      "185.240.149.33 - - [25/Jan/2019:21:28:06 +0330] \"GET /static/images/next.png HTTP/1.1\" 200 3045 \"https://znbl.ir/static/bundle-bundle_site_head.css\" \"Mozilla/5.0 (Windows NT 6.1; rv:64.0) Gecko/20100101 Firefox/64.0\" \"-\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# получим объект из файла\n",
    "#test_file = open(\"../morozov_ea/input_data/access-Copy1_short.log\", \"r\") # -обрезанная версиея логов для тестов\n",
    "test_file = open(\"../morozov_ea/input_data/access-Copy1.log\", \"r\")\n",
    "\n",
    "# считываем все строки\n",
    "rows = test_file.readlines()\n",
    "\n",
    "# закрываем файл\n",
    "test_file.close\n",
    "\n",
    "print(f'Количество строк в файле логов = {len(rows):_} \\n'.replace(\"_\", \" \"))\n",
    "print('Образец данных:\\n')\n",
    "for row in sample(rows, 3):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb585245",
   "metadata": {},
   "source": [
    "Данные выглядят весьма грязными и слабоструктурированными. Можно заметить, что подходящие для анализа блоки информации есть, но они представлены в текстовом формате и чаще всего замусорены окружающими символами, скорее всего потребуется большой объём предобработки. Выделим для себя присутствие практически во всех записях информации о:\n",
    "- IP-адресе с которого происходило обращение к сайту\n",
    "- Временной метке события\n",
    "- Кодах ответа сервера\n",
    "- Записях User_Agent  \n",
    "\n",
    "***\n",
    "\n",
    "## 4. Extract. <a class=\"anchor\" id=\"4\"></a>\n",
    "\n",
    "Из смысловых блоков, перечисленных выше, последовательно попробуем извлечь нужные данные и сохраним их в подходящем для дальнейшего анализа и преобразований виде.  \n",
    "\n",
    "Поскольку файл логов занимает ощутимый объём (3.5 гБ слабоструктурироавнных записей), то для экономии ресурсов предполагалось последовательно обрабатывать логи по частям и дописывать их в датафрейм **Pandas** по мере завершения обработки, пока все записи из файла не оказались бы в датафрейме. Однако в ходе выполнения и отработки этапов оказалось вполне возможным обработать записи за 1 проход, чем автор и воспользовался."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93d62429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 1e+03 ns, total: 2 µs\n",
      "Wall time: 4.05 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10365152"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "# сформируем тестовый образец для обаботки строк таблицы\n",
    "#rows_sample = sample(rows, 2000000)\n",
    "rows_sample = rows.copy()            # копируем данные в рабочий список, очищаем исходный rows   \n",
    "rows.clear()\n",
    "\n",
    "len(rows_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d52ee7",
   "metadata": {},
   "source": [
    "### Извлечение признаков. <a class=\"anchor\" id=\"4.1\"></a>\n",
    "\n",
    "Разделим строки записей по блокам, создав для этого список значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48ea7d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting the rows of data: 100%|\u001b[32m██████████\u001b[0m| 10365152/10365152 [01:22<00:00, 125357.62it/s]\n",
      "Deleting empties: 100%|\u001b[32m██████████\u001b[0m| 10365152/10365152 [00:09<00:00, 1123350.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример записи:\n",
      "\n",
      " ['54.36.149.41', '[22/Jan/2019:03:56:14 +0330]', 'GET /filter/27|13%20%D9%85%DA%AF%D8%A7%D9%BE%DB%8C%DA%A9%D8%B3%D9%84,27|%DA%A9%D9%85%D8%AA%D8%B1%20%D8%A7%D8%B2%205%20%D9%85%DA%AF%D8%A7%D9%BE%DB%8C%DA%A9%D8%B3%D9%84,p53 HTTP/1.1', '200 30577', 'Mozilla/5.0 (compatible; AhrefsBot/6.1; +http://ahrefs.com/robot/)']\n",
      "\n",
      " ['31.56.96.51', '[22/Jan/2019:03:56:16 +0330]', 'GET /image/60844/productModel/200x200 HTTP/1.1', '200 5667', 'https://www.zanbil.ir/m/filter/b113', 'Mozilla/5.0 (Linux; Android 6.0; ALE-L21 Build/HuaweiALE-L21) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.158 Mobile Safari/537.36']\n",
      "\n",
      " ['31.56.96.51', '[22/Jan/2019:03:56:16 +0330]', 'GET /image/61474/productModel/200x200 HTTP/1.1', '200 5379', 'https://www.zanbil.ir/m/filter/b113', 'Mozilla/5.0 (Linux; Android 6.0; ALE-L21 Build/HuaweiALE-L21) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.158 Mobile Safari/537.36']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# создаём функцию для первичной очистки строк лога от лишних данных\n",
    "\n",
    "def cleaning(rows):\n",
    "    new_rows = [] # в ходе очистки строк лога будем наполнять новый список новыми записями\n",
    "\n",
    "    for element in tqdm(rows, desc='Splitting the rows of data', colour='green'):\n",
    "        element = re.split('- -|\"-\"|\"', element.strip()) #split с использованием regular_expressions\n",
    "        \n",
    "        for i in range(len(element)):\n",
    "            element[i] = element[i].strip() #перед добавлением в список обрезаем пробелы у каждой строки\n",
    "        \n",
    "        new_rows.append(element)\n",
    "        \n",
    "    for j in tqdm(range(len(new_rows)), desc='Deleting empties', colour='green'):\n",
    "        while '' in new_rows[j]:\n",
    "            new_rows[j].remove('') #для каждой записи удаляем пустые элементы\n",
    "    rows.clear()\n",
    "    return new_rows #функция возвращает список строк (из записей лога), строки разделёны на блоки по разделителям\n",
    "\n",
    "# по каждой строке-объекту получим список с признаками, при дальнейшей обработке сократим количество элементов\n",
    "# до необходимого кол-ва, а также обработаем сами значения\n",
    "raw_data_all_features = cleaning(rows_sample)\n",
    "\n",
    "print('Пример записи:')\n",
    "for row in raw_data_all_features[:3]:\n",
    "    print('\\n', row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1856bd",
   "metadata": {},
   "source": [
    "Не все записи после \"разложения\" оказываются достаточно информативными. Отсеим те из них, которые несут слишком мало информации и не позволят в дальнейшем идентифицировать устройства по содержащимся данным.  \n",
    "\n",
    "В качестве критерия качества предполагается проверять длинну получившихся строк: если в строке пропущено слишком много смысловых блоков, то надёжней отбросить такие записи из рассмотрения, чем добавлять в некую \"суррогатную\" категорию и усложнять дальнейший анализ. Ближайшее рассмотрение показывает, что среди таких строк содержатся как повторяющиеся целиком записи, так и совпадающие частично, но в любом случае не дающие достаточно инфомрации для дальнейшей идентификации записи и отнесения её в какую-либо категорию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0070103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Looking data for uninformative rows: 100%|\u001b[32m██████████\u001b[0m| 10365152/10365152 [00:02<00:00, 4140638.28it/s]\n",
      "Deleting uninformative rows: 100%|\u001b[32m██████████\u001b[0m| 10365152/10365152 [16:05<00:00, 10736.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Малоинформативными являются 14353 строки.\n",
      "В полученном списке 10350799 строк\n"
     ]
    }
   ],
   "source": [
    "# создаём функцию для удаления малоинформативных записей и получаем очищенный список на выходе.\n",
    "\n",
    "def cleaning_uninf(rows):\n",
    "    drop_that_rows = []                         # пустой список для индексов строк годных для удаления\n",
    "    for i in tqdm(range(len(rows)), desc='Looking data for uninformative rows', colour='green'):\n",
    "        if len(rows[i]) < 5:   # принятый критерий отсеивания строк\n",
    "            drop_that_rows.append(i)\n",
    "    \n",
    "    rows_without_dropped = []                   # список для \"полезных\" записей\n",
    "    for i in tqdm(range(len(rows)), desc='Deleting uninformative rows', colour='green'):\n",
    "        if i in drop_that_rows:\n",
    "            i += 1\n",
    "        else:\n",
    "            rows_without_dropped.append(rows[i])\n",
    "            \n",
    "    print(f'Малоинформативными являются {len(drop_that_rows)} строки.')\n",
    "    print(f'В полученном списке {len(rows_without_dropped)} строк')\n",
    "    \n",
    "    rows.clear()\n",
    "    drop_that_rows.clear()\n",
    "    \n",
    "    return rows_without_dropped\n",
    "\n",
    "raw_data_all_features = cleaning_uninf(raw_data_all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b765b1e8",
   "metadata": {},
   "source": [
    "Данные пока остаются сырыми, но начало структурирования положено. Выделим целевые значения в отдельный список и последовательно приведём их к человекочитаемому формату."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcdc0917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating a list with working data (4 columns istead of 6): 100%|\u001b[32m██████████\u001b[0m| 10350799/10350799 [00:21<00:00, 480765.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример записи:\n",
      "\n",
      " ['54.36.149.41', '[22/Jan/2019:03:56:14 +0330]', '200 30577', 'Mozilla/5.0 (compatible; AhrefsBot/6.1; +http://ahrefs.com/robot/)']\n",
      "\n",
      " ['31.56.96.51', '[22/Jan/2019:03:56:16 +0330]', '200 5667', 'Mozilla/5.0 (Linux; Android 6.0; ALE-L21 Build/HuaweiALE-L21) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.158 Mobile Safari/537.36']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# получим сокращённый список значений (4 признака вместо 6) для парсинга в более понятном виде \n",
    "raw_data_4f = []\n",
    "for k in tqdm(range(len(raw_data_all_features))\n",
    "              , desc='Creating a list with working data (4 columns istead of 6)'\n",
    "              , colour='green'):\n",
    "    raw_data_4f.append([\n",
    "                        raw_data_all_features[k][0],\n",
    "                        raw_data_all_features[k][1],\n",
    "                        raw_data_all_features[k][3],\n",
    "                        raw_data_all_features[k][-1]\n",
    "                       ])\n",
    "\n",
    "raw_data_all_features.clear() # очищаем список raw_data_all_features\n",
    "\n",
    "print('Пример записи:')\n",
    "for row in raw_data_4f[:2]:\n",
    "    print('\\n', row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb4512d",
   "metadata": {},
   "source": [
    "- Блок информации с IP-адресом похоже не требует обработки, в силу уникальности содержащихся в нём значений кажется, что это поле можно использовать как суррогатный ключ устройства, проверим это предположение далее.\n",
    "\n",
    "    Выделим информацию из записи, связанной со временем события. Значение +0330 отбросим, поскольку оно везде одинаковое, в случае если оно подразумевает временную зону можно будет добавить соотв. timedelta к преобразованным значениям позже (на данном этапе было не понятно нужно или нет учитывать это)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60204973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dates extraction: 100%|\u001b[32m██████████\u001b[0m| 10350799/10350799 [00:22<00:00, 464198.05it/s]\n",
      "converting dates to datetime-format: 100%|\u001b[32m██████████\u001b[0m| 10350799/10350799 [01:36<00:00, 106926.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример записи:\n",
      "\n",
      "[datetime.datetime(2019, 1, 22, 3, 56, 14), '22-01-2019 03:56:14']\n",
      "[datetime.datetime(2019, 1, 22, 3, 56, 16), '22-01-2019 03:56:16']\n",
      "[datetime.datetime(2019, 1, 22, 3, 56, 16), '22-01-2019 03:56:16']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# функция для обработки значений столбца с датами\n",
    "\n",
    "def date_transformer(dates):\n",
    "    dates_list = []\n",
    "    for date in tqdm(dates                                   #с пом. reg.expr отделим даты от текста по шаблону\n",
    "                     , desc='dates extraction'\n",
    "                     , colour='green'):          \n",
    "        dates_list.append(re.findall(\"[^'[][\\w\\/:]*[^\\+0330\\]']\", date[1]))\n",
    "        \n",
    "    for l in tqdm(range(len(dates_list))                     #преобразуем значения в datetime и наполним список\n",
    "                  , desc='converting dates to datetime-format'\n",
    "                  , colour='green'):\n",
    "        dates_list[l][0] = dates_list[l][0].strip()          #обрезаем пробелы вначале и вконце\n",
    "        \n",
    "        # с пом. методов strptime и strftime пишем в соответствие каждому элементу 2 значения:\n",
    "        # - в формате datetime из строки и в более человекочитаемом виде из datetime\n",
    "        dates_list[l][0] = datetime.strptime(dates_list[l][0], '%d/%b/%Y:%H:%M:%S')   \n",
    "        dates_list[l].append(dates_list[l][0].strftime('%d-%m-%Y %H:%M:%S'))\n",
    "        \n",
    "    return dates_list                                 # функция возвращает список с преобразованными датами\n",
    "\n",
    "# получаем список с преобразованными датами\n",
    "dates_list = date_transformer(raw_data_4f)\n",
    "\n",
    "print('Пример записи:\\n')\n",
    "for row in dates_list[:3]:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e50fe7",
   "metadata": {},
   "source": [
    "- Записи с кодами ответа сервера можно разделить на 2 части и очистить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9a3c535",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "server's answers converting: 100%|\u001b[32m██████████\u001b[0m| 10350799/10350799 [00:14<00:00, 702469.67it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример записи:\n",
      "\n",
      "['200', '30577']\n",
      "['200', '5667']\n",
      "['200', '5379']\n",
      "['200', '1696']\n",
      "['200', '41483']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# функция для обработки значений столбца кодами состояния HTTP\n",
    "\n",
    "def serv_answers(answers):\n",
    "    serv_answers_list = []\n",
    "    for answer in tqdm(answers\n",
    "                       , desc=\"server's answers converting\"\n",
    "                       , colour='green'):              # для каждой записи разделяем ответ на 2 части:\n",
    "        serv_answers_list.append(answer[2].strip().split())\n",
    "        \n",
    "    return serv_answers_list                           # функция возвращает список с кодами ответов сервера\n",
    "\n",
    "# получаем список с преобразованными кодами состояния HTTP\n",
    "serv_answers_list = serv_answers(raw_data_4f)\n",
    "\n",
    "print('Пример записи:\\n')\n",
    "for row in serv_answers_list[:5]:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23091e63",
   "metadata": {},
   "source": [
    "- Наибольшая часть работы по извлечению данных приходится на записи User_Agent.  \n",
    "    \n",
    "    Из них предстоит извлечь информацию об использовавшемся устройстве, его операционной системе и используемом браузере. Проделаем операции в несколько этапов, разделяя строку на блоки по смысловому содержанию с помощью регулярных выражений и методов работы со строками **python**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b9c3521",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "User_Agent info splitting into device+browser info: 100%|\u001b[32m██████████\u001b[0m| 10350799/10350799 [00:48<00:00, 214572.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример записи:\n",
      "\n",
      "['compatible; AhrefsBot/6.1; +http://ahrefs.com/robot/']\n",
      "['Linux; Android 6.0; ALE-L21 Build/HuaweiALE-L21', 'Chrome/66.0.3359.158 Mobile Safari/537.36']\n",
      "['Linux; Android 6.0; ALE-L21 Build/HuaweiALE-L21', 'Chrome/66.0.3359.158 Mobile Safari/537.36']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# функция для предв. обработки значений столбца User_Agent\n",
    "\n",
    "def dev_browsers(lines):\n",
    "    dev_browsers_list = []\n",
    "    for line in tqdm(lines\n",
    "                     , desc=\"User_Agent info splitting into device+browser info\"\n",
    "                     , colour='green'):               # каждую запись разделяем на 2: инф. об устройстве и браузере\n",
    "        dev_browsers_list.append([*re.findall(\"\\(([\\w\\s.;:\\-\\/+@]+)\\)\", line[-1]),\n",
    "                                  *re.findall(\"\\w\\) {1}([\\w\\/\\s.]+$)\", line[-1])])\n",
    "        \n",
    "    return dev_browsers_list                          # функция возвращает список с соотв. значениями User_Agent\n",
    "\n",
    "# получаем список с предварительно разделёнными на 2 групппы значениями User_Agent\n",
    "# пригодный для выделения искомых данных об устройстве, ОС, браузере\n",
    "dev_browsers_list = dev_browsers(raw_data_4f)\n",
    "\n",
    "print('Пример записи:\\n')\n",
    "for row in dev_browsers_list[:3]:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b534d1",
   "metadata": {},
   "source": [
    "* Далее из этих записей выделим информацию об устройстве, ОС и браузере.  \n",
    "\n",
    "    Логика выделения довольно условна и имеет несколько умозрительный характер, сопоставления с имеющимися в интернете базами данных для определния User_Agent в рамках учебной работы не проводилось в силу ограниченности врменных ресурсов. Судя по полученной картине, ситуация с записями User_Agent исторически сложилась весьма скверным образом: одни браузеры оформляли записи так, чтобы они выглядели как заголовки других браузеров, на стандартизированную запись о модели устройства также не приходится рассчитывать - всё это сделало задачу довольно сложной и неприятной в решении.\n",
    "\n",
    "    В учебных целях автор пытался реализовать \"упрощённую\" логику парсинга: по шаблонам и ключевым словам отфильтровать и очистить записи так, чтобы полученному результату можно было сопоставить пару значений {ОС, наименование устройства}, некоторые оставшиеся исключения фильтровались по дополнительным условиям для удаления лишней информации.\n",
    "\n",
    "    Аналогичными приёмами из второй части записи получались данные об используемом браузере (предполагается, что информацию об этом можно найти в одном из блоков с названиями браузеров в записи User_Agent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b417b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция обработки данных из User_Agent для выделения инф. об устройстве и ОС\n",
    "\n",
    "def os_dev(raw_list):\n",
    "    dev_browsers_list_os = []                       # подготовим пустой список для сбора в него записей для  \n",
    "                                                    # последующей обработки и выделения инф. об устройстве и ОС    \n",
    "    for el in tqdm(raw_list, desc='creating a list of devices + OS', colour='green'):\n",
    "        if el != []:\n",
    "            dev_browsers_list_os.append(el[0])\n",
    "        else:\n",
    "            dev_browsers_list_os.append('parse_bot')\n",
    "    \n",
    "    os_dev_list = []                                # в итоговый список будут попадать записи на основании инф. из  \n",
    "                                                    # промежуточного списка после разнообразной фильтрации\n",
    "    \n",
    "    # проходим в цикле по всем элементам промежуточного списка с сырыми значениями и заносим значия в новый\n",
    "    for el in tqdm(dev_browsers_list_os, desc='parsing of raw devices_&_OS list', colour='green'):\n",
    "        \n",
    "        # ветвления и логика:\n",
    "        if ('android' in el.lower()):               # сопоставление android\n",
    "            if ('tablet' in el.lower()) or ('mobile' in el.lower()):\n",
    "                os_dev_list.append(['android',\n",
    "                                    'tablet/mobile'])\n",
    "            elif ('build' in el.lower()):\n",
    "                if (' wv' in el.lower()):\n",
    "                    os_dev_list.append(['android',\n",
    "                                        (' ').join(el.split(' build/')[0].split('; ')[-2].split(' ')[:-1])\n",
    "                                        .lower().strip()])\n",
    "                else:\n",
    "                    os_dev_list.append(['android',\n",
    "                                        (' ').join(el.split(' build/')[0].split('; ')[-1].split(' ')[:-1])\n",
    "                                        .lower().strip()])\n",
    "            elif ('rv:' in el.lower()):\n",
    "                os_dev_list.append(['android',\n",
    "                                    'tablet/mobile'])\n",
    "                \n",
    "            else:\n",
    "                os_dev_list.append(['android',\n",
    "                                    el.split('; ')[-1].lower()])\n",
    "\n",
    "        elif ('linux' in el.lower()):    # сопоставление Linux_device\n",
    "            if ('x86' in el.lower()) or ('_64' in el.lower()):\n",
    "                os_dev_list.append(['linux',\n",
    "                                    'x64'])\n",
    "            else:\n",
    "                os_dev_list.append(['linux',\n",
    "                                    'smart-tv'])\n",
    "\n",
    "        elif ('iphone' in el.lower()):   # сопоставление iPhone/iPad\n",
    "            os_dev_list.append(['iOS',\n",
    "                                ((' ').join(el.split('; ')[-1].split(' ')[1:4:2]).lower().strip())\n",
    "                                .split('_')[0]])\n",
    "            \n",
    "        elif ('ipad' in el.lower()):     # сопоставление iPhone/iPad\n",
    "            os_dev_list.append(['iOS',\n",
    "                                ((' ').join(['ipad', el.split('CPU OS ')[1][0:5]]).lower().strip())\n",
    "                                 .split('_')[0]])\n",
    "\n",
    "        elif ('macintosh' in el.lower()):           # сопоставление macintosh\n",
    "            os_dev_list.append(['macOS',\n",
    "                                (' ').join(el.split('; Intel ')).lower().strip()\n",
    "                                .split('_')[0]])\n",
    "\n",
    "        elif ('windows' in el.lower()):             # сопоставление WinPC\n",
    "            os_dev_list.append(['windows',\n",
    "                                'x64'])\n",
    "\n",
    "        else:\n",
    "            os_dev_list.append(['parse_bot', 'parse_bot'])       # сопоставление боту\n",
    "    \n",
    "    os_dev_list_changed = []   #итоговый список для сбора реузльтов обработки\n",
    "    \n",
    "    # проходим в цикле по всем элементам полученного списка os_dev_list и правим их (по результатам анализа),\n",
    "    # заполняем список os_dev_list_changed с конечными результатами\n",
    "    for el in tqdm(os_dev_list, desc='secondary parsing of devices_&_OS list', colour='green'):\n",
    "        \n",
    "        # ветвления и логика:\n",
    "        if (\n",
    "            ('' in el) | ('+989389109071' in el) | ('-1' in el) | ('2014817' in el)\n",
    "            | ('2014817 miui/v7.1.3.0.khjmick' in el) | ('2014817 miui/v9.2.5.0.lhjmiek' in el)\n",
    "            | ('2014813 miui/v66.55.22.00.khjcncd' in el) | ('2014817 miui/v8.0.2.0.khjmidg' in el)\n",
    "            | ('10' in el) | ('109v82_gq3016' in el) | ('2013' in el) | ('2014811' in el)\n",
    "           ):\n",
    "            os_dev_list_changed.append([el[0],'unknown_device'])\n",
    "\n",
    "        else:\n",
    "            os_dev_list_changed.append(el)\n",
    "    \n",
    "    dev_browsers_list_os.clear()\n",
    "    os_dev_list.clear()\n",
    "    \n",
    "    return os_dev_list_changed                      # функция возвращает список с инф. об устройстве и ОС на осн.\n",
    "                                                    # данных из User_Agent в той же последовательности\n",
    "\n",
    "\n",
    "# функции обработки данных из User_Agent для выделения инф. о браузере\n",
    "\n",
    "def browsers(raw_list):\n",
    "    dev_browsers_list_br = []                       # подготовим пустой список для сбора в него записей для  \n",
    "                                                    # последующей обработки и выделения инф. о браузерах    \n",
    "    for el in tqdm(dev_browsers_list, desc='creating a list of browsers', colour='green'):\n",
    "        if len(el) == 2:\n",
    "            dev_browsers_list_br.append(el[-1])\n",
    "        else:\n",
    "            dev_browsers_list_br.append('parse_bot')\n",
    "    \n",
    "    browsers_list = []                              # в итоговый список будут попадать записи на основании инф. из  \n",
    "                                                    # промежуточного списка после разнообразной фильтрации    \n",
    "    # проходим в цикле по всем элементам промежуточного списка с сырыми значениями и заносим значия в новый\n",
    "    for el in tqdm(dev_browsers_list_br, desc='parsing of raw browsers list', colour='green'):\n",
    "        \n",
    "        # ветвления и логика:\n",
    "        if ('like gecko' in el.lower()):\n",
    "            browsers_list.append(['IE'])              # сопоставление IE\n",
    "        elif ('bing' in el.lower()):\n",
    "            browsers_list.append(['Bing'])            # сопоставление Bing\n",
    "        elif ('bot' in el.lower()) or ('pars' in el.lower()):\n",
    "            browsers_list.append(['parse_bot'])       # сопоставление боту\n",
    "        elif ('gecko/' in el.lower()):\n",
    "            browsers_list.append([el.split(' ')[-1].split('/')[0]])      # сопоставление 1 браузеру\n",
    "        elif ('safari' in el.lower()) and ('gsa' in el.lower()):\n",
    "            browsers_list.append(['Safari'])          # сопоставление Safari на iOS-устройствах\n",
    "        else:\n",
    "            tmp = list(filter(None, re.split('[\\/\\d.\\s]+', el)))         # сопоставление нескольким браузерам,\n",
    "            if 'Mobile' in tmp:                                          # а также очистка промежуточного списка\n",
    "                tmp.remove('Mobile')                                     # от \"мусорных\" записей\n",
    "            if 'Version' in tmp:\n",
    "                tmp.remove('Version')\n",
    "            for el_tmp in tmp:\n",
    "                if (0<len(el_tmp.lower())<4):\n",
    "                    tmp.remove(el_tmp)\n",
    "            browsers_list.append(tmp)\n",
    "    \n",
    "    browsers_list_changed = []   #итоговый список для сбора реузльтов обработки\n",
    "    \n",
    "    # проходим в цикле по всем элементам полученного списка browsers_list и правим их (по результатам анализа),\n",
    "    # заполняем список browsers_list_changed с конечными результатами\n",
    "    for el in tqdm(browsers_list, desc='secondary parsing of browsers list', colour='green'):\n",
    "        \n",
    "        # ветвления и логика:\n",
    "        if (('edition' in el) | ('Edition' in el) | ('C' in el)):\n",
    "            browsers_list_changed.append(['Opera'])\n",
    "        elif ('compatible;' in el):\n",
    "            browsers_list_changed.append(['Chrome'])\n",
    "        elif ('dpi;' in el):\n",
    "            browsers_list_changed.append(['Puffin'])\n",
    "        elif (('AppleWebKit' in el) | ('libcurl' in el) | ('ngx_lua' in el)):\n",
    "            browsers_list_changed.append(['parse_bot'])\n",
    "        elif (('a' in el) | ('c' in el) | ('e' in el)):\n",
    "            browsers_list_changed.append(['Safari'])\n",
    "        elif (('Ubuntu' in el) | ('snap' in el)):\n",
    "            browsers_list_changed.append(['Chromium'])\n",
    "        elif (('1895054983' in el) | ('254054377' in el) | ('gecko' in el)):\n",
    "            browsers_list_changed.append(['Firefox'])\n",
    "        elif (('ggpht' in el)):\n",
    "            browsers_list_changed.append(['email_client'])\n",
    "        elif (('+https:' in el)):\n",
    "            browsers_list_changed.append(['Google Web Snippet'])\n",
    "        elif (('zanbil' in el)):\n",
    "            browsers_list_changed.append(['wkhtmltoimage'])\n",
    "        elif (('chromeframe' in el)):\n",
    "            browsers_list_changed.append(['IE'])\n",
    "        elif (('Android' in el)):\n",
    "            browsers_list_changed.append(['Dolphin'])\n",
    "        elif ('Baidu;' in el):\n",
    "            browsers_list_changed.append(['Baidu'])\n",
    "        \n",
    "        else:\n",
    "            browsers_list_changed.append(el)\n",
    "\n",
    "    dev_browsers_list_br.clear()\n",
    "    browsers_list.clear()\n",
    "    \n",
    "    return browsers_list_changed                     # функция возвращает список с инф. о браузерах на осн.\n",
    "                                                     # данных из User_Agent в той же последовательности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064872de",
   "metadata": {},
   "source": [
    "Получим списки с данными, преобразованными функциями выше, и сведём их в итоговый список, в котором будет запись об 1 браузере на каждое устройство. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43a85363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.48 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "creating a list of devices + OS: 100%|\u001b[32m██████████\u001b[0m| 10350799/10350799 [00:02<00:00, 3731730.27it/s]\n",
      "parsing of raw devices_&_OS list: 100%|\u001b[32m██████████\u001b[0m| 10350799/10350799 [00:18<00:00, 555351.15it/s] \n",
      "secondary parsing of devices_&_OS list: 100%|\u001b[32m██████████\u001b[0m| 10350799/10350799 [00:06<00:00, 1700363.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина списка os_dev_list (ОС+устройство) = 10350799 строк.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "creating a list of browsers: 100%|\u001b[32m██████████\u001b[0m| 10350799/10350799 [00:02<00:00, 3545831.72it/s]\n",
      "parsing of raw browsers list: 100%|\u001b[32m██████████\u001b[0m| 10350799/10350799 [00:34<00:00, 303134.47it/s]\n",
      "secondary parsing of browsers list: 100%|\u001b[32m██████████\u001b[0m| 10350799/10350799 [00:08<00:00, 1180266.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина списка browsers_list (используемый браузер) = 10350799 строк.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "creating of united device/OS/browser list: 100%|\u001b[32m██████████\u001b[0m| 10350799/10350799 [00:17<00:00, 585242.45it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример записи:\n",
      "\n",
      "['parse_bot', 'parse_bot', 'parse_bot']\n",
      "['android', 'ale-l21', 'Chrome']\n",
      "['android', 'ale-l21', 'Chrome']\n",
      "['parse_bot', 'parse_bot', 'parse_bot']\n",
      "['windows', 'x64', 'parse_bot']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%time                                               # вдобавок к tqdm будем контролировать время исполнения кода\n",
    "\n",
    "# получим списки с информацией из User_Agent в отдельные списки заносим данные об устройствах+ОС и о браузерах\n",
    "os_dev_list = os_dev(dev_browsers_list)\n",
    "print('Длина списка os_dev_list (ОС+устройство) =', len(os_dev_list), 'строк.')\n",
    "\n",
    "browsers_list = browsers(dev_browsers_list)\n",
    "print('Длина списка browsers_list (используемый браузер) =', len(browsers_list), 'строк.')\n",
    "\n",
    "dev_browsers_list.clear()\n",
    "\n",
    "# функции для отдельной сведения информации из списков с данными об устройствах/ОС/браузерах в единый список\n",
    "\n",
    "def dev_os_br_union(os_dev_list, dev_browsers_list):\n",
    "    united_list = []                                # подготовим пустой список для сбора записей\n",
    "    \n",
    "    # проходим в цикле по всем элементам списков, созданных выше (os_dev_list, browsers_list)\n",
    "    # и заносим значия в итоговый чтобы 1 устройству соответствовал 1 браузер исходя из простой логики\n",
    "    for i in tqdm(range(len(os_dev_list)), desc='creating of united device/OS/browser list', colour='green'):\n",
    "        \n",
    "        # ветвления и логика:\n",
    "        if len(dev_browsers_list[i]) > 1:\n",
    "            united_list.append([*os_dev_list[i], dev_browsers_list[i][0]])\n",
    "        else:\n",
    "            united_list.append([*os_dev_list[i], *dev_browsers_list[i]])\n",
    "            \n",
    "    return united_list                              # функция возвращает список с общей информацией с записями в\n",
    "                                                    # той же последовательности что была в User_Agent\n",
    "\n",
    "# получим список с информацией об устройствах+ОС и о браузерах в одной записи\n",
    "united_usag_list = dev_os_br_union(os_dev_list, browsers_list)\n",
    "\n",
    "os_dev_list.clear()\n",
    "browsers_list.clear()\n",
    "\n",
    "print('Пример записи:\\n')\n",
    "for row in united_usag_list[:5]:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5226cb95",
   "metadata": {},
   "source": [
    "### Сведение полученных признаков. <a class=\"anchor\" id=\"4.2\"></a>\n",
    "\n",
    "Предварительная обработка закончена, не везде результаты парсинга получились \"аккуратными\", но для учебных целей итог, кажется, можно считать достаточным. Дальнейшая подготовка заняла бы чрезмерное время, остановимся на достигнутом результате.\n",
    "\n",
    "- Далее подготовим и сведём всю иформацию в датафрейм **Pandas**.  \n",
    "\n",
    "    В целом, на вопросы задания можно ответить, пользуясь лишь этой библиотекой для обработки, но в силу того, что курс старался привить студентам навыки инженера данных, **Pandas** будет использоваться как эффективное, но не конечное звено в обработке, подрбнее о причинах и альтенативах выбора сказано ниже.\n",
    "    \n",
    "    Данные в виде Pandas.DataFrame будет удобно:\n",
    "\n",
    "    1. обрабатывать как непосредственно методами самой библиотеки **Pandas**,  \n",
    "\n",
    "    2. так и транслировать данные из него в иные форматы для обработки вне библиотеки **Pandas**. Это будет логично, если данные, скажем:  \n",
    "\n",
    "        - не помещаются в оперативную память компьютера, и требуется обработка на кластере (что может быть эффективнее, чем на локальной \"машине\", хоть и требует иного инструментария),\n",
    "        - или же иной формат предполагатеся более практичным или устойчивым в \"промышленном\" применении,  \n",
    "    \n",
    "    3. трансформацию и преобразование данных предполагается осуществлять с пом. фреймворка **Spark**, а в него с версии 3.2 внедрены методы **Pandas** на уровне API, что скорее всего будет способствовать удобству работы с имеющимся датафреймом.  \n",
    "    \n",
    "    4. Вдобавок к этому **Spark** предлагает лаконичную форму работы как с **Hive SQL** (т.е. БД будет возможно хранить в распределённом виде), так и простоту подключения к БД **PostgreSQL**, что также предположительно может сократить путь до выгрузки итоговой витрины.\n",
    "\n",
    "Прежде, чем создать датафрейм **Pandas**, подготовим словарь с необходимыми данными в виде полученных выше списков значений.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fa40c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "collecting from ip_addr_list: 100%|\u001b[33m██████████\u001b[0m| 10350799/10350799 [00:04<00:00, 2207416.30it/s]\n",
      "collecting from date_list: 100%|\u001b[33m██████████\u001b[0m| 10350799/10350799 [00:02<00:00, 5087080.65it/s]\n",
      "collecting from serv_answer_1_list: 100%|\u001b[33m██████████\u001b[0m| 10350799/10350799 [00:01<00:00, 5187492.88it/s]\n",
      "collecting from serv_answer_2_list: 100%|\u001b[33m██████████\u001b[0m| 10350799/10350799 [00:01<00:00, 5322285.32it/s]\n",
      "collecting from device_list: 100%|\u001b[33m██████████\u001b[0m| 10350799/10350799 [00:01<00:00, 5620854.07it/s]\n",
      "collecting from os_list: 100%|\u001b[33m██████████\u001b[0m| 10350799/10350799 [00:01<00:00, 5985918.96it/s]\n",
      "collecting from browser_list: 100%|\u001b[33m██████████\u001b[0m| 10350799/10350799 [00:01<00:00, 5276965.55it/s]\n",
      "converting data formats: 100%|\u001b[32m██████████\u001b[0m| 3/3 [00:17<00:00,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Описание данных и первые 5 строк полученного датафрейма:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10350799 entries, 0 to 10350798\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Dtype         \n",
      "---  ------         -----         \n",
      " 0   addr           int64         \n",
      " 1   date           datetime64[ns]\n",
      " 2   serv_answer_1  int64         \n",
      " 3   serv_answer_2  int64         \n",
      " 4   device         object        \n",
      " 5   os             object        \n",
      " 6   browser        object        \n",
      "dtypes: datetime64[ns](1), int64(3), object(3)\n",
      "memory usage: 552.8+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addr</th>\n",
       "      <th>date</th>\n",
       "      <th>serv_answer_1</th>\n",
       "      <th>serv_answer_2</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>browser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>543614941</td>\n",
       "      <td>2019-01-22 03:56:14</td>\n",
       "      <td>200</td>\n",
       "      <td>30577</td>\n",
       "      <td>parse_bot</td>\n",
       "      <td>parse_bot</td>\n",
       "      <td>parse_bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31569651</td>\n",
       "      <td>2019-01-22 03:56:16</td>\n",
       "      <td>200</td>\n",
       "      <td>5667</td>\n",
       "      <td>ale-l21</td>\n",
       "      <td>android</td>\n",
       "      <td>Chrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31569651</td>\n",
       "      <td>2019-01-22 03:56:16</td>\n",
       "      <td>200</td>\n",
       "      <td>5379</td>\n",
       "      <td>ale-l21</td>\n",
       "      <td>android</td>\n",
       "      <td>Chrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4077167129</td>\n",
       "      <td>2019-01-22 03:56:17</td>\n",
       "      <td>200</td>\n",
       "      <td>1696</td>\n",
       "      <td>parse_bot</td>\n",
       "      <td>parse_bot</td>\n",
       "      <td>parse_bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91997215</td>\n",
       "      <td>2019-01-22 03:56:17</td>\n",
       "      <td>200</td>\n",
       "      <td>41483</td>\n",
       "      <td>x64</td>\n",
       "      <td>windows</td>\n",
       "      <td>parse_bot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         addr                date  serv_answer_1  serv_answer_2     device  \\\n",
       "0   543614941 2019-01-22 03:56:14            200          30577  parse_bot   \n",
       "1    31569651 2019-01-22 03:56:16            200           5667    ale-l21   \n",
       "2    31569651 2019-01-22 03:56:16            200           5379    ale-l21   \n",
       "3  4077167129 2019-01-22 03:56:17            200           1696  parse_bot   \n",
       "4    91997215 2019-01-22 03:56:17            200          41483        x64   \n",
       "\n",
       "          os    browser  \n",
       "0  parse_bot  parse_bot  \n",
       "1    android     Chrome  \n",
       "2    android     Chrome  \n",
       "3  parse_bot  parse_bot  \n",
       "4    windows  parse_bot  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# интересующие нас значения хранятся в списках ниже, составим из них словарь:\n",
    "'''\n",
    "ip_addr_list   # -этот список создаётся в коде ниже\n",
    "dates_list\n",
    "serv_answers_list\n",
    "united_usag_list\n",
    "'''\n",
    "\n",
    "# список с IP-адресами предполагается использовать в качестве суррогатного ключа,\n",
    "# сделаем его значения более похожими на ключи - преобразуем адрес и одно число:\n",
    "ip_addr_list = [('').join(el[0].split('.')).strip() for el in tqdm(raw_data_4f\n",
    "                                                                   , desc = 'collecting from ip_addr_list'\n",
    "                                                                   , colour = 'YELLOW')]\n",
    "\n",
    "# некоторая обработка потребуется и для значений списков, хранящих по несколько элементов\n",
    "# в строках в виде вложенных списков, получим из них отдельные столбцы значений:\n",
    "date = [el[0] for el in tqdm(dates_list\n",
    "                             , desc = 'collecting from date_list'\n",
    "                             , colour = 'YELLOW')]\n",
    "\n",
    "serv_answer_1 = [el[0] for el in tqdm(serv_answers_list\n",
    "                                      , desc = 'collecting from serv_answer_1_list'\n",
    "                                      , colour = 'YELLOW')]\n",
    "serv_answer_2 = [el[1] for el in tqdm(serv_answers_list\n",
    "                                      , desc = 'collecting from serv_answer_2_list'\n",
    "                                      , colour = 'YELLOW')]\n",
    "\n",
    "device = [el[1] for el in tqdm(united_usag_list\n",
    "                               , desc = 'collecting from device_list'\n",
    "                               , colour = 'YELLOW')]\n",
    "os = [el[0] for el in tqdm(united_usag_list\n",
    "                           , desc = 'collecting from os_list'\n",
    "                           , colour = 'YELLOW')]\n",
    "browser = [el[-1] for el in tqdm(united_usag_list\n",
    "                                 , desc = 'collecting from browser_list'\n",
    "                                 , colour = 'YELLOW')]\n",
    "\n",
    "# сводим всё в словарь для создания датафрейма Pandas\n",
    "data_dict = {\n",
    "    'addr' : ip_addr_list,\n",
    "    'date' : date,\n",
    "    'serv_answer_1' : serv_answer_1,\n",
    "    'serv_answer_2' : serv_answer_2,\n",
    "    'device' : device,\n",
    "    'os' : os,\n",
    "    'browser' : browser\n",
    "}\n",
    "\n",
    "# создаём dataframe\n",
    "df = pd.DataFrame(data = data_dict)\n",
    "\n",
    "# исправим форматы данных на числовые для колонок 'addr', 'serv_answer_1', 'serv_answer_2'\n",
    "for i in tqdm([0, 2, 3], desc = 'converting data formats', colour = 'green'):\n",
    "    df[df.columns[i]] = pd.to_numeric(df[df.columns[i]], errors='raise', downcast=None)\n",
    "    #df[df.columns[i]] = df[df.columns[i]].astype('int') - либо так\n",
    "\n",
    "# выведем информацию о таблице и первые 5 строк полученного датафрейма:\n",
    "print('Описание данных и первые 5 строк полученного датафрейма:\\n')\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a678c8",
   "metadata": {},
   "source": [
    "По условию задания необходимо добавить суррогатные уникальные ключи к устройствам, с которых осуществлялся запрос, также предполагалось использовать IP-адрес в качестве такого ключа при подходящей возможности. Проверим, подойдут ли для этого какие-нибудь столбцы датафрейма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4199ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во уникальных значений в столбце df[\"addr\"] = 257702\n",
      "Кол-во уникальных значений в столбце df[\"device\"] = 3379\n",
      "Кол-во уникальных значений в столбце df[\"os\"] = 6\n"
     ]
    }
   ],
   "source": [
    "for el in ['addr', 'device', 'os']:\n",
    "    print(f'Кол-во уникальных значений в столбце df[\"{el}\"] = {len(df[el].unique())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8769fc2d",
   "metadata": {},
   "source": [
    "Дополнительно сгруппируем данные по перечисленным выше столбцам и посчитаем кол-во записей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e3eddbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "addr          device     os     \n",
       "51219136      2pq93      android      1\n",
       "315676189     2pyb2      android    164\n",
       "51131253      4035d      android     19\n",
       "5113247247    4035d      android     20\n",
       "51211230      5047d      android      2\n",
       "                                   ... \n",
       "2181146236    zuk z2131  android     37\n",
       "5119169104    zuk z2131  android      2\n",
       "19518117325   zuk z2131  android      1\n",
       "151232238181  zuk z2131  android     91\n",
       "5106122168    zuk z2151  android     36\n",
       "Name: device, Length: 281664, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "df.groupby(by = ['addr', 'device', 'os'])['device']\n",
    "    .count()\n",
    "    .sort_values(ascending = False)\n",
    "    .sort_index(level = 'device')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d120df",
   "metadata": {},
   "source": [
    "Очевидно, что есть повторяющиеся значения и использовать встроенный индекс dataframe в качестве уник. ключей будет неверно. По сути уникальность записи определяется комбинацией полей {устройство; ОС}, ведь и IP-адрес и браузер при этом могут меняться. Сформируем суррогатные ключи для соотв. записей на основании указанных полей {устройство; ОС}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e8d3062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3376</th>\n",
       "      <td>3376</td>\n",
       "      <td>zte grand s ii lte</td>\n",
       "      <td>android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3377</th>\n",
       "      <td>3377</td>\n",
       "      <td>zuk z1</td>\n",
       "      <td>android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3378</th>\n",
       "      <td>3378</td>\n",
       "      <td>zuk z2121</td>\n",
       "      <td>android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3379</th>\n",
       "      <td>3379</td>\n",
       "      <td>zuk z2131</td>\n",
       "      <td>android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3380</th>\n",
       "      <td>3380</td>\n",
       "      <td>zuk z2151</td>\n",
       "      <td>android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index              device       os\n",
       "3376   3376  zte grand s ii lte  android\n",
       "3377   3377              zuk z1  android\n",
       "3378   3378           zuk z2121  android\n",
       "3379   3379           zuk z2131  android\n",
       "3380   3380           zuk z2151  android"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получим индекс по уникальным сочетаниям полей 'device' и 'os' для чего сгруппируем\n",
    "# данные и сбросим индекс, чтобы получить столбец с ключами из значений индекса pd.Series \n",
    "\n",
    "index = (\n",
    "    df\n",
    "    .groupby(by = ['device', 'os'])['addr']\n",
    "    .count()\n",
    "    .sort_index(level = ['device', 'os'])\n",
    "    .reset_index()\n",
    "    .reset_index()\n",
    "    .drop(columns = 'addr')\n",
    ")\n",
    "\n",
    "index.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d54a772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Таблица приняла следующий вид:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>serv_answer_1</th>\n",
       "      <th>serv_answer_2</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>browser</th>\n",
       "      <th>dev_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>543614941</td>\n",
       "      <td>2019-01-22 03:56:14</td>\n",
       "      <td>200</td>\n",
       "      <td>30577</td>\n",
       "      <td>parse_bot</td>\n",
       "      <td>parse_bot</td>\n",
       "      <td>parse_bot</td>\n",
       "      <td>1882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31569651</td>\n",
       "      <td>2019-01-22 03:56:16</td>\n",
       "      <td>200</td>\n",
       "      <td>5667</td>\n",
       "      <td>ale-l21</td>\n",
       "      <td>android</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31569651</td>\n",
       "      <td>2019-01-22 03:56:16</td>\n",
       "      <td>200</td>\n",
       "      <td>5379</td>\n",
       "      <td>ale-l21</td>\n",
       "      <td>android</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id                date  serv_answer_1  serv_answer_2     device  \\\n",
       "0  543614941 2019-01-22 03:56:14            200          30577  parse_bot   \n",
       "1   31569651 2019-01-22 03:56:16            200           5667    ale-l21   \n",
       "2   31569651 2019-01-22 03:56:16            200           5379    ale-l21   \n",
       "\n",
       "          os    browser  dev_key  \n",
       "0  parse_bot  parse_bot     1882  \n",
       "1    android     Chrome       76  \n",
       "2    android     Chrome       76  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# объединим таблицы df и index по полям 'device' и 'os' чтобы добавить поле с ключами к df\n",
    "# удалять поле 'addr' не станем, т.к. оно позволит выделять разных пользователей устройств\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    .merge(index\n",
    "           , how = 'left'\n",
    "           , suffixes = ('', '_index')\n",
    "           , left_on = ['device', 'os']\n",
    "           , right_on = ['device', 'os'])\n",
    ")\n",
    "\n",
    "# переименуем столбцы 'index' в 'dev_key' и 'addr' в 'user_id'\n",
    "df.rename(columns = {'index':'dev_key', 'addr':'user_id'}, inplace=True)\n",
    "print('Таблица приняла следующий вид:')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c331df",
   "metadata": {},
   "source": [
    "Полученная таблица приняла вид достаточный для дальнейшего анализа и постороения витрины данных. Удалять поле 'addr' с изменённым IP-адресом, с которого отправлялся запрос к сайту, не станем, поскольку оно в моём понимании позволит выделять разных пользователей в случае, если бы они использовали устройства одинаковых моделей. Будем считать, что IP-адреса характеризуют сессии разных пользователей. Поменяем названия на более понятные.  \n",
    "\n",
    "### Сохранение датафрейма.  <a class=\"anchor\" id=\"4.3\"></a>\n",
    "\n",
    "\n",
    "На данном этапе появляется возможность сохраниь полученный датафрейм в формате, желаемом  для обработки на последующих стадиях создания витрины данных. Предполагается, что форматы **AVRO**, **Parquet** или **ORC** более предпочтительны нежели **CSV**, поскольку являются колоночными, поддерживают сжатие, встраивание схемы данных и приспособлены для распределённого хранения. Выполним эту операцию в учебных целях, а в ходе дальнейшей работы обращаться можно будет как к полученному файлу, так и к переменной ***df***, хранящей pandas.DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "117263a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.77 µs\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10350799 entries, 0 to 10350798\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Dtype         \n",
      "---  ------         -----         \n",
      " 0   user_id        int64         \n",
      " 1   date           datetime64[ns]\n",
      " 2   serv_answer_1  int64         \n",
      " 3   serv_answer_2  int64         \n",
      " 4   device         object        \n",
      " 5   os             object        \n",
      " 6   browser        object        \n",
      " 7   dev_key        int64         \n",
      "dtypes: datetime64[ns](1), int64(4), object(3)\n",
      "memory usage: 710.7+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>serv_answer_1</th>\n",
       "      <th>serv_answer_2</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>browser</th>\n",
       "      <th>dev_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>543614941</td>\n",
       "      <td>2019-01-22 03:56:14</td>\n",
       "      <td>200</td>\n",
       "      <td>30577</td>\n",
       "      <td>parse_bot</td>\n",
       "      <td>parse_bot</td>\n",
       "      <td>parse_bot</td>\n",
       "      <td>1882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31569651</td>\n",
       "      <td>2019-01-22 03:56:16</td>\n",
       "      <td>200</td>\n",
       "      <td>5667</td>\n",
       "      <td>ale-l21</td>\n",
       "      <td>android</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31569651</td>\n",
       "      <td>2019-01-22 03:56:16</td>\n",
       "      <td>200</td>\n",
       "      <td>5379</td>\n",
       "      <td>ale-l21</td>\n",
       "      <td>android</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id                date  serv_answer_1  serv_answer_2     device  \\\n",
       "0  543614941 2019-01-22 03:56:14            200          30577  parse_bot   \n",
       "1   31569651 2019-01-22 03:56:16            200           5667    ale-l21   \n",
       "2   31569651 2019-01-22 03:56:16            200           5379    ale-l21   \n",
       "\n",
       "          os    browser  dev_key  \n",
       "0  parse_bot  parse_bot     1882  \n",
       "1    android     Chrome       76  \n",
       "2    android     Chrome       76  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "# сохраним датафрейм в формате parque и откроем его \n",
    "# (для проверки свойств полученного файла: скорость загрузки, форматы данных, схема, занимаемый объём памяти)\n",
    "\n",
    "df.to_parquet(path='../morozov_ea/output_data/parsed_logs_df.parquet', index=None)\n",
    "\n",
    "df_parquet = pd.read_parquet('../morozov_ea/output_data/parsed_logs_df.parquet')\n",
    "\n",
    "print(df_parquet.info())\n",
    "df_parquet.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5541bd",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## 5. Transform. <a class=\"anchor\" id=\"5\"></a>\n",
    "\n",
    "Ответы на вопросы задания получим в несколько этапов: как с использованием кластерных вычислений так и в локальном режиме (во время разработки пользовался сокращённой выборкой, которая в память одной машины вполне помещалась, соответственно этот абзац писался до получения решения на полном датафрейме).\n",
    "\n",
    "### 5.1. Решение в Pandas.  <a class=\"anchor\" id=\"5.1\"></a>\n",
    "\n",
    "Для ориентира получим ответы на вопросы задания с использованием библиотеки **Pandas**, затем будем использовать их для сравнения с результатами во фреймворке **Spark**. Формулировки заданий не везде можно было понять однозначно, буду пояснять своё трактование параллельно с предпринимаемыми действиями.  \n",
    "\n",
    "***\n",
    "\n",
    "#### *пункты 1-4*  <a class=\"anchor\" id=\"5.1.1\"></a>  \n",
    "\n",
    "- Выведем сперва:  \n",
    "\n",
    "    ***1.*** *Суррогатный ключ устройства.*  \n",
    "    ***2.*** *Название устройства.*  \n",
    "    ***3.*** *Количество пользователей.*  \n",
    "    ***4.*** *Доля пользователей данного устройства от общего числа пользователей.*  \n",
    "\n",
    "По принятому предположению в качестве уникальных пользователей считаются непоторяющиеся записи {'user_id', 'device'}, сгруппируем данные по этим полям и дате запроса и подсчитаем количества вхождений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e903c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>serv_answer_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev_key</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">3379</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">151232238181</th>\n",
       "      <th>2019-01-22 22:26:20</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-22 22:26:22</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-22 22:26:32</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-22 22:26:38</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-22 22:26:39</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-22 22:26:41</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-22 22:26:42</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">3380</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">5106122168</th>\n",
       "      <th>2019-01-24 00:59:29</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-24 00:59:31</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-24 00:59:32</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-24 00:59:33</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-24 00:59:34</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-24 00:59:37</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-24 00:59:38</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-24 00:59:44</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          serv_answer_2\n",
       "dev_key user_id      date                              \n",
       "3379    151232238181 2019-01-22 22:26:20              2\n",
       "                     2019-01-22 22:26:22              4\n",
       "                     2019-01-22 22:26:32              1\n",
       "                     2019-01-22 22:26:38              2\n",
       "                     2019-01-22 22:26:39              3\n",
       "                     2019-01-22 22:26:41              1\n",
       "                     2019-01-22 22:26:42              6\n",
       "3380    5106122168   2019-01-24 00:59:29              1\n",
       "                     2019-01-24 00:59:31             11\n",
       "                     2019-01-24 00:59:32              4\n",
       "                     2019-01-24 00:59:33              8\n",
       "                     2019-01-24 00:59:34              5\n",
       "                     2019-01-24 00:59:37              3\n",
       "                     2019-01-24 00:59:38              1\n",
       "                     2019-01-24 00:59:44              3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.groupby(['dev_key', 'user_id', 'date']).count()['serv_answer_2']).tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d524698",
   "metadata": {},
   "source": [
    "Видно, что запросы к сайту приходили как от пользователей с \"человеческим\" поведением, так и из других источников (в общем случае обозначаемых как \"parse_bot\"), единичные обращения то имеют временной интревал между собой, то следуют сразу пакетами. Тем не менее, в качестве отдельных пользователей стоит считать именно запросы с разных устройств с различающимся 'user_id', их будет больше, чем отдельных записей 'user_id', подсчитаем такие сочетания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98caa307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device</th>\n",
       "      <th>users_qty</th>\n",
       "      <th>users_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2pq93</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2pyb2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4035d</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5047d</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5049w</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3376</th>\n",
       "      <td>zte grand s ii lte</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3377</th>\n",
       "      <td>zuk z1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3378</th>\n",
       "      <td>zuk z2121</td>\n",
       "      <td>15</td>\n",
       "      <td>0.00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3379</th>\n",
       "      <td>zuk z2131</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3380</th>\n",
       "      <td>zuk z2151</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3381 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     device  users_qty  users_ratio\n",
       "dev_key                                            \n",
       "0                     2pq93          1      0.00000\n",
       "1                     2pyb2          1      0.00000\n",
       "2                     4035d          2      0.00001\n",
       "3                     5047d          6      0.00002\n",
       "4                     5049w          1      0.00000\n",
       "...                     ...        ...          ...\n",
       "3376     zte grand s ii lte          4      0.00001\n",
       "3377                 zuk z1          4      0.00001\n",
       "3378              zuk z2121         15      0.00005\n",
       "3379              zuk z2131          9      0.00003\n",
       "3380              zuk z2151          1      0.00000\n",
       "\n",
       "[3381 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# кол-во строк в группе, т.е. кол-во запросов с разных устройств с разным user_id\n",
    "unique_users_qty = len(df.groupby(['dev_key', 'user_id']))\n",
    "\n",
    "# датафрейм по п.1-4\n",
    "df_1_4 = (\n",
    "    df\n",
    "    .groupby(['dev_key', 'device', 'user_id'])\n",
    "    .any()['serv_answer_2']\n",
    "    .reset_index()\n",
    "    .groupby('dev_key')\n",
    "    .agg({'device':'first', 'user_id':'count'})\n",
    "    .rename(columns={'user_id':'users_qty'})\n",
    ")\n",
    "\n",
    "df_1_4['users_ratio'] = np.round((df_1_4['users_qty'] / unique_users_qty), 5)\n",
    "df_1_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecba22c",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "#### *пункты 5-6*  <a class=\"anchor\" id=\"5.1.2\"></a>  \n",
    "\n",
    "- Сгруппируем данные и дополним витрину информацией о (cуррогатный ключ и название устройства также остаются актуальными):  \n",
    "\n",
    "    ***5.*** *Количество совершенных действий для данного устройства.*  \n",
    "    ***6.*** *Доля совершенных действий с данного устройства, относительно других устройств.*  \n",
    "   \n",
    "    \n",
    "Аналогично предыдущему предположению, уникальми дейсвтиями будем считать непоторяющиеся варианты кодов в полях {'serv_answer_1', 'serv_answer_2'} для разных устройств, сгруппируем данные по этим полям и дате запроса для всех упомянутых устройств и подсчитаем количества вхождений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bc4af2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev_key</th>\n",
       "      <th>serv_answer_1</th>\n",
       "      <th>serv_answer_2</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"10\" valign=\"top\">200</th>\n",
       "      <th>2542</th>\n",
       "      <th>2019-01-24 17:45:08</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <th>2019-01-24 17:44:05</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <th>2019-01-24 17:34:46</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <th>2019-01-24 17:34:14</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <th>2019-01-24 17:41:37</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <th>2019-01-24 17:34:13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <th>2019-01-24 17:34:36</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <th>2019-01-24 17:27:32</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <th>2019-01-24 17:42:31</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <th>2019-01-24 17:33:14</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         user_id\n",
       "dev_key serv_answer_1 serv_answer_2 date                        \n",
       "1       200           2542          2019-01-24 17:45:08        1\n",
       "                      2749          2019-01-24 17:44:05        1\n",
       "                      2784          2019-01-24 17:34:46        1\n",
       "                      2885          2019-01-24 17:34:14        1\n",
       "                      2967          2019-01-24 17:41:37        1\n",
       "                      2975          2019-01-24 17:34:13        1\n",
       "                      2986          2019-01-24 17:34:36        1\n",
       "                      2987          2019-01-24 17:27:32        1\n",
       "                      3038          2019-01-24 17:42:31        1\n",
       "                      3047          2019-01-24 17:33:14        1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.groupby(['dev_key', 'serv_answer_1', 'serv_answer_2', 'date']).count()['user_id'])[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96442400",
   "metadata": {},
   "source": [
    "Судя по полученным значениям столбцов (с добавлением дат), обращения к сайту вполне могли осуществляться в разные даты, с разных адресов ('user_id' в нашем случае) и из разных бразуеров, получая, однако, одни и теже коды ответов сервера.  \n",
    "\n",
    "Поскольку в данном задании речь шла именно об отношении \"устройство-действие\", а не \"устройство-пользователь-действие\" или более подробном, то под \"дейсвтием\" будем понимать упомянутые выше непоторяющиеся варианты кодов в полях {'serv_answer_1', 'serv_answer_2'} для устройств с различающимся 'dev_key'. \n",
    "\n",
    "Получающаяся величина может трактоваться как возможные на данном устройстве варианты ответов сервера: но не суммарное количество запросов, а именно количество комбинаций - т.е. некоторые устройства в этом смысле могут обладать широким диапазоном действий, а некоторые - отправлять только считанное число запросов. Подсчитаем такие сочетания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d0b476a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device</th>\n",
       "      <th>answers_qty</th>\n",
       "      <th>answers_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2pq93</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2pyb2</td>\n",
       "      <td>139</td>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4035d</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5047d</td>\n",
       "      <td>83</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5049w</td>\n",
       "      <td>137</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3376</th>\n",
       "      <td>zte grand s ii lte</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3377</th>\n",
       "      <td>zuk z1</td>\n",
       "      <td>72</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3378</th>\n",
       "      <td>zuk z2121</td>\n",
       "      <td>103</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3379</th>\n",
       "      <td>zuk z2131</td>\n",
       "      <td>205</td>\n",
       "      <td>0.000159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3380</th>\n",
       "      <td>zuk z2151</td>\n",
       "      <td>36</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3381 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     device  answers_qty  answers_ratio\n",
       "dev_key                                                \n",
       "0                     2pq93            1       0.000001\n",
       "1                     2pyb2          139       0.000108\n",
       "2                     4035d           26       0.000020\n",
       "3                     5047d           83       0.000064\n",
       "4                     5049w          137       0.000106\n",
       "...                     ...          ...            ...\n",
       "3376     zte grand s ii lte            4       0.000003\n",
       "3377                 zuk z1           72       0.000056\n",
       "3378              zuk z2121          103       0.000080\n",
       "3379              zuk z2131          205       0.000159\n",
       "3380              zuk z2151           36       0.000028\n",
       "\n",
       "[3381 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# кол-во строк в группе, т.е. кол-во ответов сервера с различными 'serv_answer_1' и 'serv_answer_2'\n",
    "unique_answers_qty = len(df.groupby(['dev_key', 'serv_answer_1', 'serv_answer_2']))\n",
    "\n",
    "# датафрейм по п.5-6\n",
    "df_5_6 = (\n",
    "    df\n",
    "    .groupby(['dev_key', 'device', 'serv_answer_1', 'serv_answer_2'])\n",
    "    .any()['user_id']\n",
    "    .reset_index()\n",
    "    .groupby('dev_key')\n",
    "    .agg({'device':'first', 'serv_answer_2':'count'})\n",
    "    .rename(columns={'serv_answer_2':'answers_qty'})\n",
    ")\n",
    "\n",
    "df_5_6['answers_ratio'] = np.round((df_5_6['answers_qty'] / unique_answers_qty), 6)\n",
    "df_5_6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dc6c14",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "#### *пункт 7*  <a class=\"anchor\" id=\"5.1.3\"></a>  \n",
    "\n",
    "- Ещё раз сгруппируем данные и дополним витрину (cуррогатный ключ и название устройства также остаются актуальными) данными о браузерах:\n",
    "\n",
    "    ***7.*** *Список из 5 самых популярных браузеров, используемых на данном устройстве различными пользователями, с указанием доли использования для данного браузера относительно остальных браузеров.*\n",
    "    \n",
    "Из строки со сведениями User_agent парсились данные только по наименованию браузера (без номеров версий), а также в соотв. случаях добавлялись записи вида \"parse_bot\", поэтому список самых полулярных браузеров для каждой модели устройств далеко не всегда будет состоять из 5 записей. Сгруппируем данные по полям 'dev_key' и 'browser', для исключения повторных названий поле 'user_id' добавлять в группировку не станем. Браузер всегда использовался с тем или иным 'user_id' и популярность можно сравнить по подсчёту количества вошедших записей без более глубокого разделения. \n",
    "\n",
    "Задание было несколько изменено: предлагается наряду с моделью и наименованием популярных на этом устройстве браузеров, выводить по кадому из них:\n",
    "- количество использований (штук на данном устройстве),\n",
    "- долю их применения от общего количества использований браузеров на данном устройстве,\n",
    "- а также долю использования данного браузера от общего кол-ва применений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a26a1f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3466686/952812859.py:14: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_7_br_by_dev = df_7.copy().reset_index().groupby('dev_key').sum()                        #группир-ка по устр-ву\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>usage_qty</th>\n",
       "      <th>ratio_by_device</th>\n",
       "      <th>ratio_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev_key</th>\n",
       "      <th>device</th>\n",
       "      <th>browser</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>2pq93</th>\n",
       "      <th>Chrome</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.48032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2pyb2</th>\n",
       "      <th>Chrome</th>\n",
       "      <td>160</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.48032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parse_bot</th>\n",
       "      <td>4</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.15273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>4035d</th>\n",
       "      <th>Chrome</th>\n",
       "      <td>39</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.48032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>5047d</th>\n",
       "      <th>Chrome</th>\n",
       "      <td>84</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.48032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          usage_qty  ratio_by_device  ratio_total\n",
       "dev_key device browser                                           \n",
       "0       2pq93  Chrome             1            1.000      0.48032\n",
       "1       2pyb2  Chrome           160            0.976      0.48032\n",
       "               parse_bot          4            0.024      0.15273\n",
       "2       4035d  Chrome            39            1.000      0.48032\n",
       "3       5047d  Chrome            84            0.840      0.48032"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# датафрейм по п.7\n",
    "df_7 = (\n",
    "    pd.DataFrame(\n",
    "        df\n",
    "        .groupby(['dev_key', 'device', 'browser'])\n",
    "        .count()['date']\n",
    "        )\n",
    ")\n",
    "\n",
    "# дополнения (временные таблицы) для слияния с df_7 и получения расчётных величин\n",
    "df_7_br_tot = df_7.copy().reset_index().groupby('browser').agg({'date':'sum'})             #группир-ка по браузеру    \n",
    "df_7_br_tot['ratio_total'] = np.round(df_7_br_tot['daскринte'] / df_7_br_tot['date'].sum(), 5)  #расчёт доли от общего\n",
    "\n",
    "df_7_br_by_dev = df_7.copy().reset_index().groupby('dev_key').sum()                        #группир-ка по устр-ву\n",
    "                                                                                           #расчёт кол-ва применений\n",
    "# объединения таблиц\n",
    "df_7 = df_7.merge(df_7_br_by_dev, how='left', left_index=True, right_index=True)\n",
    "df_7['ratio_by_device'] = np.round(df_7['date_x'] / df_7['date_y'], 3)\n",
    "df_7 = df_7.merge(df_7_br_tot, how='left', left_index=True, right_index=True)\n",
    "\n",
    "# удаление лишних столбцов, переименование\n",
    "df_7.drop(columns = ['date_y', 'date'], inplace = True)\n",
    "df_7.rename(columns = {'date_x' : 'usage_qty'}, inplace = True)\n",
    "df_7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cca05c",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "#### *пункты 8-9*  <a class=\"anchor\" id=\"5.1.4\"></a>  \n",
    "\n",
    "- Дополним витрину (cуррогатный ключ и название устройства также остаются актуальными) данными об ответах сервера: \n",
    "\n",
    "    ***8.*** *Количество ответов сервера, отличных от 200, на данном устройстве.*  \n",
    "    ***9.*** *Для каждого из ответов сервера, отличных от 200, сформировать поле, в котором будет содержаться количество ответов данного типа.*  \n",
    "    \n",
    "В данном вопросе достаточно будет сгруппировать датафрейм по ключам 'dev_key' и 'serv_answer_1' для строк, в которых значение ответа не равно 200, а также поститать такие вхождения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85fedae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>not200_sum_by_device</th>\n",
       "      <th>not200_answers_qty</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev_key</th>\n",
       "      <th>device</th>\n",
       "      <th>serv_answer_1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>2pyb2</th>\n",
       "      <th>302</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>4035d</th>\n",
       "      <th>302</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>5047d</th>\n",
       "      <th>302</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">5049w</th>\n",
       "      <th>301</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3377</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">zuk z1</th>\n",
       "      <th>404</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3378</th>\n",
       "      <th>zuk z2121</th>\n",
       "      <th>302</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3379</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">zuk z2131</th>\n",
       "      <th>302</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4794 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 not200_sum_by_device  not200_answers_qty\n",
       "dev_key device    serv_answer_1                                          \n",
       "1       2pyb2     302                               2                   2\n",
       "2       4035d     302                               8                   8\n",
       "3       5047d     302                               2                   2\n",
       "4       5049w     301                               2                   1\n",
       "                  302                               2                   1\n",
       "...                                               ...                 ...\n",
       "3377    zuk z1    404                              11                   3\n",
       "                  499                              11                   1\n",
       "3378    zuk z2121 302                               4                   4\n",
       "3379    zuk z2131 302                               7                   5\n",
       "                  499                               7                   2\n",
       "\n",
       "[4794 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# датафрейм для п.8-9 без строк с отвтеом 200\n",
    "df_8_9 = (\n",
    "    pd.DataFrame(\n",
    "        df\n",
    "        .loc[df.loc[:, 'serv_answer_1'] != 200, :]\n",
    "        .groupby(['dev_key', 'device', 'serv_answer_1'])\n",
    "        .count()['serv_answer_2']\n",
    "    ).rename(columns = {'serv_answer_2' : 'not200_answers_qty'})\n",
    ")\n",
    "\n",
    "# добавляем столбец с суммарным кол-вом ответов, отличных от 200 + transform для распространения на все строки    \n",
    "df_8_9['not200_sum_by_device'] = df_8_9.groupby(level = 'dev_key').transform('sum')\n",
    "\n",
    "# меняем порядок следования столбцов\n",
    "df_8_9 = df_8_9.reindex(columns = ['not200_sum_by_device', 'not200_answers_qty'])\n",
    "df_8_9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685e7c5d",
   "metadata": {},
   "source": [
    "В целях унификации можно объединить ответы п.1-6, но датафреймы п.7 и п.8-9 получились не столь подобными, их имеет смысл рассматривать отдельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e9e1be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device</th>\n",
       "      <th>users_qty</th>\n",
       "      <th>users_ratio</th>\n",
       "      <th>answers_qty</th>\n",
       "      <th>answers_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2pq93</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2pyb2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>139</td>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4035d</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5047d</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>83</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5049w</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>137</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        device  users_qty  users_ratio  answers_qty  answers_ratio\n",
       "dev_key                                                           \n",
       "0        2pq93          1      0.00000            1       0.000001\n",
       "1        2pyb2          1      0.00000          139       0.000108\n",
       "2        4035d          2      0.00001           26       0.000020\n",
       "3        5047d          6      0.00002           83       0.000064\n",
       "4        5049w          1      0.00000          137       0.000106"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# витрина по пунктам 1-6 задания\n",
    "df_1_6 = (\n",
    "    df_1_4\n",
    "    .merge(df_5_6\n",
    "           , how='left'\n",
    "           , left_index = True\n",
    "           , right_index = True\n",
    "           , suffixes = ('','_right'))\n",
    "    .drop(columns = ['device_right'])\n",
    ")\n",
    "\n",
    "df_1_6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3914f37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>usage_qty</th>\n",
       "      <th>ratio_by_device</th>\n",
       "      <th>ratio_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev_key</th>\n",
       "      <th>device</th>\n",
       "      <th>browser</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>2pq93</th>\n",
       "      <th>Chrome</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.48032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2pyb2</th>\n",
       "      <th>Chrome</th>\n",
       "      <td>160</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.48032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parse_bot</th>\n",
       "      <td>4</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.15273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>4035d</th>\n",
       "      <th>Chrome</th>\n",
       "      <td>39</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.48032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>5047d</th>\n",
       "      <th>Chrome</th>\n",
       "      <td>84</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.48032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          usage_qty  ratio_by_device  ratio_total\n",
       "dev_key device browser                                           \n",
       "0       2pq93  Chrome             1            1.000      0.48032\n",
       "1       2pyb2  Chrome           160            0.976      0.48032\n",
       "               parse_bot          4            0.024      0.15273\n",
       "2       4035d  Chrome            39            1.000      0.48032\n",
       "3       5047d  Chrome            84            0.840      0.48032"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# витрина по пункту 7 задания\n",
    "df_7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b634a48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>not200_sum_by_device</th>\n",
       "      <th>not200_answers_qty</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev_key</th>\n",
       "      <th>device</th>\n",
       "      <th>serv_answer_1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>2pyb2</th>\n",
       "      <th>302</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>4035d</th>\n",
       "      <th>302</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>5047d</th>\n",
       "      <th>302</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">5049w</th>\n",
       "      <th>301</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              not200_sum_by_device  not200_answers_qty\n",
       "dev_key device serv_answer_1                                          \n",
       "1       2pyb2  302                               2                   2\n",
       "2       4035d  302                               8                   8\n",
       "3       5047d  302                               2                   2\n",
       "4       5049w  301                               2                   1\n",
       "               302                               2                   1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# витрина по пунктам 8-9 задания\n",
    "df_8_9.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdae1c26",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Решение получено с помощью **pandas** не только потому, что этот инструмент удобен и по-своему эффективен (пока что в силу \"бесшовности\" перехода от low-level обработки на Python к абстракциям в виде pandas.DataFrame, чтобы избежать преобразований в SQL-базу данных), но и с целью продолжить использование библиотеки на дальнейших стадиях выстраиваемого pipeline обработки данных.  \n",
    "\n",
    "Выгружать из памяти полученные таблицы не станем, поскольку их вызов может понадобится при написании кода в **Spark** для сравнения и трансляции методов. Сохранять результаты в том или ином формате для отображения их в качестве промежуточного решения на \"голом\" **pandas** также пока не станем, поскольку задачи строгой экономии ресурсов не стоит.  \n",
    "\n",
    "***\n",
    "\n",
    "### 5.2. Решение в Spark.  <a class=\"anchor\" id=\"5.2\"></a>  \n",
    "\n",
    "Для курса по инженерии данных представляется логичным воспользоваться иными инструментами data engeneer: в первую очередь инструментами стэка для работы с параллельными вычислениями и распределёнными данными, - и перенести решение на эту платформу.  \n",
    "\n",
    "Первейшим из таких инструментов выглядит использование фреймворка **Apache Spark**. \n",
    "\n",
    "Предполагается достичь этим нескольких целей:  \n",
    "\n",
    "- во время выполнения учебных заданий **Spark** показался довольно удобным \"мостом\" для трансляции табличных данных в традиционые реляционные базы данных и возможностью обработки данных с использованием SQL, не используя при этом промежуточные этапы в виде запросов через **Pandas**+**SQLAlchemy**/**psycopg2** и т.п.\n",
    "\n",
    "\n",
    "- вторым иснтересным аспектом работы в **Spark**, смежным с указанным выше, показалась возможность доступа к распределённому хранилищу метаданных **Hive** с использованием соответствующего языка запросов **HiveQL**.  \n",
    "  \n",
    "  Подобным преимуществом хотелось бы воспользоваться, для того, чтобы не только обработка данных была распреденной, но также и запись и доступ к данным могли бы выполняться в распределенном виде и использовать преимущества HDFS.  \n",
    " \n",
    "\n",
    "- в состав **API Spark** в свежих версиях было включено **API Pandas** именно на уровне **Structured API**, что должно позволить относительно просто использовать код решений, приведённый выше, и работать знакомыми методах не теряя в быстродействии, а также сделать какие-то сравнения с SparkSQL и pySpark.\n",
    "  \n",
    "  Это довольно интересно, поскольку одним из столпов **Pandas** является использование индексов в DataFrame, тогда как в **Spark** подобная \"механика\" не использовалась, но очевидно была перенесена в кластерную парадигму.\n",
    "\n",
    "Ниже предпринимается попытка реализации описанной выше логики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1913036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode ---  local\n",
      "23/01/09 00:44:43 WARN Utils: Your hostname, data-analysis resolves to a loopback address: 127.0.1.1; using 146.120.224.166 instead (on interface ens160)\n",
      "23/01/09 00:44:43 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/09 00:44:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "mode ---  yarn\n",
      "23/01/09 00:44:46 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "+-----+\n",
      "|hello|\n",
      "+-----+\n",
      "|spark|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# создаём Spark-сессию \n",
    "# (часто при первом запуске вылетал с ошибкой, вдобавок хотелось думать, что можно запуститься на кластере\n",
    "# поэтому методом тыка была отработана техника для входа сначала c master(\"local\"), а потом c \"yarn\")\n",
    "\n",
    "for mode in ['local', 'yarn']: \n",
    "    print('mode --- ', mode)\n",
    "    spark = (\n",
    "        SparkSession\n",
    "        .builder\n",
    "        .master(mode)\n",
    "        .appName(\"spark_pandas\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "\n",
    "# проверка работоспособности\n",
    "spark.sql('select \"spark\" as hello').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06d1b391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://146.120.224.166:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>spark_pandas</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fda27546e80>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbc9c39",
   "metadata": {},
   "source": [
    "Загрузка и сохранение файлов в **Spark** осуществляются в виде вызовов методов объекта `spark`:\n",
    "- ***`.read` -- `.format()` -- `.option()` -- `.load()`*** --> для чтения\n",
    "- ***`.write` -- `.format()` -- `.mode()` -- `.option()` -- `.save()`*** --> для записи\n",
    "\n",
    "Из прежде сохранённого в формате \"parquet\" файла загрузим датафрейм, схема должна считаться автоматически."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b462876a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- serv_answer_1: long (nullable = true)\n",
      " |-- serv_answer_2: long (nullable = true)\n",
      " |-- device: string (nullable = true)\n",
      " |-- os: string (nullable = true)\n",
      " |-- browser: string (nullable = true)\n",
      " |-- dev_key: long (nullable = true)\n",
      " |-- __index_level_0__: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    spark\n",
    "    .read\n",
    "    .format('parquet')\n",
    "    #.option(\"'path', '../... или file://....') # путь можно указать в .option()\n",
    "    .load('../morozov_ea/output_data/parsed_logs_df.parquet')\n",
    ")\n",
    "\n",
    "# выведем схему датафрейма и посмотрим тип объекта\n",
    "df.printSchema()\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98f05a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.9/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>serv_answer_1</th>\n",
       "      <th>serv_answer_2</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>browser</th>\n",
       "      <th>dev_key</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>543614941</td>\n",
       "      <td>2019-01-22 03:56:14</td>\n",
       "      <td>200</td>\n",
       "      <td>30577</td>\n",
       "      <td>parse_bot</td>\n",
       "      <td>parse_bot</td>\n",
       "      <td>parse_bot</td>\n",
       "      <td>1882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31569651</td>\n",
       "      <td>2019-01-22 03:56:16</td>\n",
       "      <td>200</td>\n",
       "      <td>5667</td>\n",
       "      <td>ale-l21</td>\n",
       "      <td>android</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31569651</td>\n",
       "      <td>2019-01-22 03:56:16</td>\n",
       "      <td>200</td>\n",
       "      <td>5379</td>\n",
       "      <td>ale-l21</td>\n",
       "      <td>android</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id                date  serv_answer_1  serv_answer_2     device         os    browser  dev_key\n",
       "index                                                                                                       \n",
       "0      543614941 2019-01-22 03:56:14            200          30577  parse_bot  parse_bot  parse_bot     1882\n",
       "1       31569651 2019-01-22 03:56:16            200           5667    ale-l21    android     Chrome       76\n",
       "2       31569651 2019-01-22 03:56:16            200           5379    ale-l21    android     Chrome       76"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pyspark.pandas.frame.DataFrame"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# конвертируем pyspark.sql.dataframe.DataFrame в датафрейм pandas-API и изменим название индекса\n",
    "pds_df = df.pandas_api(index_col='__index_level_0__')\n",
    "pds_df.index.rename('index', inplace= True)\n",
    "display(pds_df.head(3))\n",
    "type(pds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b14a562d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- serv_answer_1: long (nullable = true)\n",
      " |-- serv_answer_2: long (nullable = true)\n",
      " |-- device: string (nullable = true)\n",
      " |-- os: string (nullable = true)\n",
      " |-- browser: string (nullable = true)\n",
      " |-- dev_key: long (nullable = true)\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [__index_level_0__#15L, user_id#7L, date#8, serv_answer_1#9L, serv_answer_2#10L, device#11, os#12, browser#13, dev_key#14L]\n",
      "+- *(1) ColumnarToRow\n",
      "   +- FileScan parquet [user_id#7L,date#8,serv_answer_1#9L,serv_answer_2#10L,device#11,os#12,browser#13,dev_key#14L,__index_level_0__#15L] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/home/jupyter-morozov_evgeny/morozov_ea/output_data/parsed_logs_d..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<user_id:bigint,date:timestamp,serv_answer_1:bigint,serv_answer_2:bigint,device:string,os:s...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# выведем схему и план исполнения датафрейма pandas \n",
    "pds_df.spark.print_schema()\n",
    "pds_df.spark.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab2659a",
   "metadata": {},
   "source": [
    "Разработчики изменили названия некоторых методов, к примеру `.to_pandas_on_spark()` стал более коротким `.pandas_api()`, но по-прежнему удивляет количество перенесенных методов **pandas** в **Spark**. При переименовании колонки индекса работает даже атрибут `inplace`, а отображаемый выше датафрейм при всех изменениях остётся pyspark-объектом. Судя по всему, для работы в кластере с объектами Pandas-API достаточно указать индекс, без этого датафрейм при обработке не будет покидать память одной из машин кластера (предположение). \n",
    "\n",
    "Сравним, как решается задание в **Pandas-API** и более классичекими методами **Spark**.\n",
    "\n",
    "***\n",
    "\n",
    "###  Задания 1-4. <a class=\"anchor\" id=\"5.3\"></a>  \n",
    "\n",
    "#### --- *Pandas API* ---\n",
    "\n",
    "- Выведем:  \n",
    "\n",
    "    ***1.*** *Суррогатный ключ устройства.*  \n",
    "    ***2.*** *Название устройства.*  \n",
    "    ***3.*** *Количество пользователей.*  \n",
    "    ***4.*** *Доля пользователей данного устройства от общего числа пользователей.*  \n",
    "\n",
    "В разделе выше задача решалась следующим образом: для уникальных пользователей с непоторяющимися записями {'user_id', 'device'} производилась группировка данных и подсчитывались количества вхождений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "564724da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.9/site-packages/pyspark/pandas/internal.py:1573: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  fields = [\n",
      "/opt/tljh/user/lib/python3.9/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device</th>\n",
       "      <th>users_qty</th>\n",
       "      <th>users_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2pq93</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2pyb2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4035d</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5047d</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5049w</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5050</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5050x</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5095k</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6043d</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6p</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>702so</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>706</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>708g</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>709a</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7_plus</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8030y</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8_plus</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9002x</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9003x</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9007a</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         device  users_qty  users_ratio\n",
       "dev_key                                \n",
       "0         2pq93          1     0.000004\n",
       "1         2pyb2          1     0.000004\n",
       "2         4035d          2     0.000007\n",
       "3         5047d          6     0.000021\n",
       "4         5049w          1     0.000004\n",
       "5          5050          4     0.000014\n",
       "6         5050x          1     0.000004\n",
       "7         5095k          1     0.000004\n",
       "8         6043d          4     0.000014\n",
       "9            6p         16     0.000057\n",
       "10        702so          1     0.000004\n",
       "11          706          3     0.000011\n",
       "12         708g          1     0.000004\n",
       "13         709a          1     0.000004\n",
       "14       7_plus          2     0.000007\n",
       "15        8030y          1     0.000004\n",
       "16       8_plus          2     0.000007\n",
       "17        9002x          2     0.000007\n",
       "18        9003x          3     0.000011\n",
       "19        9007a          6     0.000021"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# кол-во запросов с разных устройств с разным user_id\n",
    "unique_users_qty = pds_df.groupby(['dev_key', 'user_id']).count().count()[0]\n",
    "\n",
    "# датафрейм по п.1-4\n",
    "pds_df_1_4 = (\n",
    "    pds_df\n",
    "    .groupby(['dev_key', 'device', 'user_id'])\n",
    "    .any()['serv_answer_2']\n",
    "    .reset_index()\n",
    "    .groupby('dev_key')\n",
    "    .agg({'device':'first', 'user_id':'count'})\n",
    "    .rename(columns={'user_id':'users_qty'})\n",
    ")\n",
    "\n",
    "pds_df_1_4['users_ratio_1'] = unique_users_qty\n",
    "pds_df_1_4['users_ratio'] = pds_df_1_4['users_qty'] / pds_df_1_4['users_ratio_1']\n",
    "pds_df_1_4 = pds_df_1_4.drop(columns = 'users_ratio_1')\n",
    "pds_df_1_4.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ccfcef",
   "metadata": {},
   "source": [
    "С некоторыми корректировками, вызванными неполным переносом всех методов в API Pandas из родной библиотеки, задача принципиально была решена в том же виде, что и в нативном **pandas** с повторением всех процедур. Тот же результат получается с использованием **spark.sql** методов (ниже).\n",
    "\n",
    "#### --- *PySpark* --- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "357da99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+-----------+\n",
      "|dev_key|device|users_qty|users_ratio|\n",
      "+-------+------+---------+-----------+\n",
      "|0      |2pq93 |1        |0.0        |\n",
      "|1      |2pyb2 |1        |0.0        |\n",
      "|2      |4035d |2        |1.0E-5     |\n",
      "|3      |5047d |6        |2.0E-5     |\n",
      "|4      |5049w |1        |0.0        |\n",
      "|5      |5050  |4        |1.0E-5     |\n",
      "|6      |5050x |1        |0.0        |\n",
      "|7      |5095k |1        |0.0        |\n",
      "|8      |6043d |4        |1.0E-5     |\n",
      "|9      |6p    |16       |6.0E-5     |\n",
      "|10     |702so |1        |0.0        |\n",
      "|11     |706   |3        |1.0E-5     |\n",
      "|12     |708g  |1        |0.0        |\n",
      "|13     |709a  |1        |0.0        |\n",
      "|14     |7_plus|2        |1.0E-5     |\n",
      "|15     |8030y |1        |0.0        |\n",
      "|16     |8_plus|2        |1.0E-5     |\n",
      "|17     |9002x |2        |1.0E-5     |\n",
      "|18     |9003x |3        |1.0E-5     |\n",
      "|19     |9007a |6        |2.0E-5     |\n",
      "+-------+------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# в переменной сохраним число записей в сгрупированном объекте \n",
    "unique_users_qty_s = df.groupBy('dev_key', 'device', 'user_id').count().count()\n",
    "\n",
    "# датафрейм по п.1-4\n",
    "s_df_1_4 = (\n",
    "    df\n",
    "    .groupBy('dev_key', 'device', 'user_id')\n",
    "    .count()\n",
    "    .select('dev_key', 'device', 'user_id')\n",
    "    .groupBy('dev_key', 'device')\n",
    "    .agg({'user_id' : 'count'})\n",
    "    .toDF('dev_key', 'device', 'users_qty')\n",
    "    .select('dev_key', 'device', 'users_qty')\n",
    "    .withColumn('users_ratio', f.round(f.col('users_qty') / unique_users_qty_s, 5))\n",
    "    .orderBy(f.asc('dev_key'))\n",
    ")\n",
    "\n",
    "s_df_1_4.show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a377f",
   "metadata": {},
   "source": [
    "#### --- *SQL-методы* ---\n",
    "\n",
    "* **метод объекта Spark-сессии**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb23f247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 28:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+-----------+\n",
      "|dev_key|device|users_qty|users_ratio|\n",
      "+-------+------+---------+-----------+\n",
      "|0      |2pq93 |1        |0.0        |\n",
      "|1      |2pyb2 |1        |0.0        |\n",
      "|2      |4035d |2        |1.0E-5     |\n",
      "|3      |5047d |6        |2.0E-5     |\n",
      "|4      |5049w |1        |0.0        |\n",
      "|5      |5050  |4        |1.0E-5     |\n",
      "|6      |5050x |1        |0.0        |\n",
      "|7      |5095k |1        |0.0        |\n",
      "|8      |6043d |4        |1.0E-5     |\n",
      "|9      |6p    |16       |6.0E-5     |\n",
      "|10     |702so |1        |0.0        |\n",
      "|11     |706   |3        |1.0E-5     |\n",
      "|12     |708g  |1        |0.0        |\n",
      "|13     |709a  |1        |0.0        |\n",
      "|14     |7_plus|2        |1.0E-5     |\n",
      "|15     |8030y |1        |0.0        |\n",
      "|16     |8_plus|2        |1.0E-5     |\n",
      "|17     |9002x |2        |1.0E-5     |\n",
      "|18     |9003x |3        |1.0E-5     |\n",
      "|19     |9007a |6        |2.0E-5     |\n",
      "+-------+------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# регистрируем таблицу как временную, чтобы драйвер видел её как SQL-таблицу\n",
    "df.createOrReplaceTempView(\"1_4\")\n",
    "\n",
    "# запрос вынесем в отдельную переменную и будем использовать её как аргумент в методе\n",
    "sql_expr = \"\"\"\n",
    "            WITH TMP_GR AS\n",
    "            (SELECT dev_key, device, user_id\n",
    "            FROM 1_4\n",
    "            GROUP BY dev_key, device, user_id\n",
    "            ORDER BY dev_key ASC)\n",
    "            \n",
    "            SELECT dev_key, device, COUNT(user_id) AS users_qty,\n",
    "                   ROUND(COUNT(user_id) / (SELECT COUNT(*) FROM TMP_GR), 5) AS users_ratio\n",
    "            FROM TMP_GR\n",
    "            GROUP BY dev_key, device\n",
    "            ORDER BY dev_key ASC\n",
    "            \"\"\"\n",
    "\n",
    "s_sql_df_1_4 = spark.sql(sql_expr)\n",
    "s_sql_df_1_4.show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135047c1",
   "metadata": {},
   "source": [
    "* **метод обектов pyspark.pandas.frame.DataFrame**\n",
    "\n",
    "    Дополнительно сравним с выводом от метода `.sql()` объектов `pyspark.pandas.frame.DataFrame`. Учтём, однако, что обекты и переменные, передаваемые методу в строке должны быть явным образом перечислены наподобие аргументов для f-строк python.  \n",
    "    \n",
    "    Удобство состоит в том, что вывод осуществляется в привычном для датафреймов **Pandas** виде, а также в утилитарном способе использования SQL-запросов к датафрейму, минуя установку специализированных библиотек наподобии **SQLAlchemy** или **Psycopg2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e6e9f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dev_key</th>\n",
       "      <th>device</th>\n",
       "      <th>users_qty</th>\n",
       "      <th>users_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2pq93</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2pyb2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4035d</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5047d</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5049w</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5050</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5050x</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>5095k</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>6043d</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>6p</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dev_key device  users_qty  users_ratio\n",
       "0        0  2pq93          1      0.00000\n",
       "1        1  2pyb2          1      0.00000\n",
       "2        2  4035d          2      0.00001\n",
       "3        3  5047d          6      0.00002\n",
       "4        4  5049w          1      0.00000\n",
       "5        5   5050          4      0.00001\n",
       "6        6  5050x          1      0.00000\n",
       "7        7  5095k          1      0.00000\n",
       "8        8  6043d          4      0.00001\n",
       "9        9     6p         16      0.00006"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_expr_pd = \"\"\"\n",
    "              WITH TMP_GR AS\n",
    "              (SELECT dev_key, device, user_id\n",
    "              FROM {pds_df}\n",
    "              GROUP BY dev_key, device, user_id\n",
    "              ORDER BY dev_key ASC)\n",
    "            \n",
    "              SELECT dev_key, device, COUNT(user_id) AS users_qty,\n",
    "                     ROUND(COUNT(user_id) / (SELECT COUNT(*) FROM TMP_GR), 5) AS users_ratio\n",
    "              FROM TMP_GR\n",
    "              GROUP BY dev_key, device\n",
    "              ORDER BY dev_key ASC\n",
    "              \"\"\"\n",
    "ps.sql(sql_expr_pd, pds_df=pds_df).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def80ecb",
   "metadata": {},
   "source": [
    "Результаты работы всех методов идентичны, все они отображены выше в учебных целях, в дальнейшем такой диапазон решеинй использоваться не будет.  \n",
    "\n",
    "Стоит отметить, что пользователь, запустив **Spark**, получает \"из коробки\" возможность работы на API Pandas, SQL а также pySpark, что по широте возможностей, кажется, делает инструмент мощным и довольно безальтернативным.  \n",
    "\n",
    "***\n",
    "\n",
    "###  Задания 5-6. <a class=\"anchor\" id=\"5.4\"></a>  \n",
    "\n",
    "#### --- *Pandas API* ---\n",
    "\n",
    "- Сгруппируем данные и дополним витрину информацией о:\n",
    "\n",
    "    ***5.*** *Количество совершенных действий для данного устройства.*  \n",
    "    ***6.*** *Доля совершенных действий с данного устройства, относительно других устройств.*\n",
    "   \n",
    "Решение приводилось в соотв. разделе выше, переложим его на синтаксис **Spark**. В качестве напоминания: уникальми дейсвтиями будем считать непоторяющиеся варианты кодов в полях {'serv_answer_1', 'serv_answer_2'} для различных устройств, сгруппируем данные по этим полям и дате запроса для всех упомянутых устройств и подсчитаем количества вхождений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9d550af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.9/site-packages/pyspark/pandas/internal.py:1573: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  fields = [\n",
      "/opt/tljh/user/lib/python3.9/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device</th>\n",
       "      <th>actions_qty</th>\n",
       "      <th>actions_ratio_by_device</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2pq93</td>\n",
       "      <td>1</td>\n",
       "      <td>7.770938e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2pyb2</td>\n",
       "      <td>139</td>\n",
       "      <td>1.080160e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4035d</td>\n",
       "      <td>26</td>\n",
       "      <td>2.020444e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5047d</td>\n",
       "      <td>83</td>\n",
       "      <td>6.449878e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5049w</td>\n",
       "      <td>137</td>\n",
       "      <td>1.064618e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5050</td>\n",
       "      <td>43</td>\n",
       "      <td>3.341503e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5050x</td>\n",
       "      <td>3</td>\n",
       "      <td>2.331281e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5095k</td>\n",
       "      <td>18</td>\n",
       "      <td>1.398769e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6043d</td>\n",
       "      <td>58</td>\n",
       "      <td>4.507144e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6p</td>\n",
       "      <td>145</td>\n",
       "      <td>1.126786e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        device  actions_qty  actions_ratio_by_device\n",
       "dev_key                                             \n",
       "0        2pq93            1             7.770938e-07\n",
       "1        2pyb2          139             1.080160e-04\n",
       "2        4035d           26             2.020444e-05\n",
       "3        5047d           83             6.449878e-05\n",
       "4        5049w          137             1.064618e-04\n",
       "5         5050           43             3.341503e-05\n",
       "6        5050x            3             2.331281e-06\n",
       "7        5095k           18             1.398769e-05\n",
       "8        6043d           58             4.507144e-05\n",
       "9           6p          145             1.126786e-04"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# кол-во строк в группе, т.е. кол-во ответов сервера с различными 'serv_answer_1' и 'serv_answer_2'\n",
    "unique_answers_qty = pds_df.groupby(['dev_key', 'serv_answer_1', 'serv_answer_2']).count().count()[0]\n",
    "\n",
    "# датафрейм по п.5-6\n",
    "pds_df_5_6 = (\n",
    "    pds_df\n",
    "    .groupby(['dev_key', 'device', 'serv_answer_1', 'serv_answer_2'])\n",
    "    .any()['user_id']\n",
    "    .reset_index()\n",
    "    .groupby('dev_key')\n",
    "    .agg({'device':'first', 'serv_answer_2':'count'})\n",
    "    .rename(columns={'serv_answer_2':'actions_qty'})\n",
    ")\n",
    "\n",
    "pds_df_5_6['actions_ratio_1'] = unique_answers_qty\n",
    "pds_df_5_6['actions_ratio_by_device'] = pds_df_5_6['actions_qty'] / pds_df_5_6['actions_ratio_1']\n",
    "pds_df_5_6 = pds_df_5_6.drop(columns = 'actions_ratio_1')\n",
    "\n",
    "pds_df_5_6.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae49df74",
   "metadata": {},
   "source": [
    "#### --- *PySpark* ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7e54b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 95:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----------+-----------------------+\n",
      "|dev_key|device|actions_qty|actions_ratio_by_device|\n",
      "+-------+------+-----------+-----------------------+\n",
      "|0      |2pq93 |1          |7.771E-7               |\n",
      "|1      |2pyb2 |139        |1.08016E-4             |\n",
      "|2      |4035d |26         |2.02044E-5             |\n",
      "|3      |5047d |83         |6.44988E-5             |\n",
      "|4      |5049w |137        |1.064618E-4            |\n",
      "|5      |5050  |43         |3.3415E-5              |\n",
      "|6      |5050x |3          |2.3313E-6              |\n",
      "|7      |5095k |18         |1.39877E-5             |\n",
      "|8      |6043d |58         |4.50714E-5             |\n",
      "|9      |6p    |145        |1.126786E-4            |\n",
      "+-------+------+-----------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 97:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# в переменной сохраним число записей в сгрупированном объекте \n",
    "unique_answers_qty_s = df.groupBy('dev_key', 'serv_answer_1', 'serv_answer_2').count().count()\n",
    "\n",
    "# датафрейм по п.5-6\n",
    "s_df_5_6 = (\n",
    "    df\n",
    "    .groupBy('dev_key', 'device', 'serv_answer_1', 'serv_answer_2')\n",
    "    .count()\n",
    "    .select('dev_key', 'device', 'serv_answer_1', 'serv_answer_2')\n",
    "    #.orderBy(f.asc('dev_key'), f.asc('serv_answer_1'), f.asc('serv_answer_2'))\n",
    "    .groupBy('dev_key', 'device')\n",
    "    .agg({'serv_answer_2' : 'count'})\n",
    "    .toDF('dev_key', 'device', 'actions_qty')\n",
    "    .withColumn('actions_ratio_by_device', f.round(f.col('actions_qty') / unique_answers_qty_s, 10))\n",
    "    .orderBy(f.asc('dev_key'))\n",
    ")\n",
    "\n",
    "s_df_5_6.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bcb739",
   "metadata": {},
   "source": [
    "Решение получилось идентичным с результатом работы на **Pandas**. Продолжим выполнение оставшихся заданий с использованием **Spark**.\n",
    "\n",
    "***\n",
    "\n",
    "###  Задание 7. <a class=\"anchor\" id=\"5.5\"></a>  \n",
    "\n",
    "#### --- *Pandas API* ---\n",
    "\n",
    "- Ещё раз сгруппируем данные и дополним витрину данными о браузерах:\n",
    "\n",
    "    ***7.*** *Список из 5 самых популярных браузеров, используемых на данном устройстве различными пользователями, с указанием доли использования для данного браузера относительно остальных браузеров.*\n",
    "    \n",
    "Комментарии к заданию остаются прежними: список самых полулярных браузеров для каждой модели устройств далеко не всегда будет состоять из 5 записей. Сгруппируем данные по полям 'dev_key' и 'browser', для исключения повторных названий поле 'user_id' добавлять в группировку не станем. Задание было несколько изменено: предлагается наряду с моделью и наименованием популярных на этом устройстве браузеров, выводить по кадому из них:\n",
    "- количество использований (штук на данном устройстве),\n",
    "- долю их применения от общего количества использований браузеров на данном устройстве,\n",
    "- а также долю использования данного браузера от общего кол-ва применений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "890caee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>usage_qty</th>\n",
       "      <th>ratio_by_device</th>\n",
       "      <th>ratio_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev_key</th>\n",
       "      <th>device</th>\n",
       "      <th>browser</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>2pq93</th>\n",
       "      <th>Chrome</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.480323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2pyb2</th>\n",
       "      <th>Chrome</th>\n",
       "      <td>160</td>\n",
       "      <td>0.97561</td>\n",
       "      <td>0.480323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parse_bot</th>\n",
       "      <td>4</td>\n",
       "      <td>0.02439</td>\n",
       "      <td>0.152727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>4035d</th>\n",
       "      <th>Chrome</th>\n",
       "      <td>39</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.480323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>5047d</th>\n",
       "      <th>Chrome</th>\n",
       "      <td>84</td>\n",
       "      <td>0.84000</td>\n",
       "      <td>0.480323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          usage_qty  ratio_by_device  ratio_total\n",
       "dev_key device browser                                           \n",
       "0       2pq93  Chrome             1          1.00000     0.480323\n",
       "1       2pyb2  Chrome           160          0.97561     0.480323\n",
       "               parse_bot          4          0.02439     0.152727\n",
       "2       4035d  Chrome            39          1.00000     0.480323\n",
       "3       5047d  Chrome            84          0.84000     0.480323"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# датафрейм по п.7\n",
    "\n",
    "#  первичная группировка и преобразование ps.Series к ps.DataFrame (для удобства)\n",
    "pds_df_7 = (\n",
    "    ps.DataFrame(\n",
    "        pds_df\n",
    "        .groupby(['dev_key', 'device', 'browser'])\n",
    "        .count()['date']\n",
    "        )\n",
    ")\n",
    "\n",
    "# дополнения (временные таблицы) для слияния с df_7 и получения расчётных величин\n",
    "pds_df_7_br_tot = pds_df_7.copy().reset_index().groupby('browser').agg({'date':'sum'})     #группир-ка по браузеру    \n",
    "pds_df_7_br_tot['ratio_total'] = pds_df_7_br_tot['date'] / pds_df_7_br_tot['date'].sum()   #расчёт доли от общего\n",
    "\n",
    "pds_df_7_br_by_dev = pds_df_7.copy().reset_index().groupby('dev_key').sum()                #группир-ка по устр-ву\n",
    "                                                                                           #расчёт кол-ва применений\n",
    "\n",
    "# объединения таблиц\n",
    "pds_df_7 = (\n",
    "    pds_df_7\n",
    "    .reset_index(level=['device','browser'])\n",
    "    .merge(pds_df_7_br_by_dev, how='left', left_index=True, right_index=True)\n",
    ")\n",
    "\n",
    "pds_df_7['ratio_by_device'] = pds_df_7['date_x'] / pds_df_7['date_y']\n",
    "\n",
    "pds_df_7 = (\n",
    "    pds_df_7\n",
    "    .merge(pds_df_7_br_tot, how='left', left_on='browser', right_index=True)\n",
    ")\n",
    "\n",
    "# удаление лишних столбцов, переименование и перезапись индекса для идентичности отображения с df_7 \n",
    "pds_df_7 = (\n",
    "    pds_df_7\n",
    "    .drop(columns = ['date_y', 'date'])\n",
    "    .rename(columns = {'date_x' : 'usage_qty'})\n",
    "    .reset_index()\n",
    "    .sort_values(by = ['dev_key', 'device', 'browser'], ascending=True)\n",
    "    .set_index(['dev_key', 'device', 'browser'])\n",
    ")\n",
    "\n",
    "pds_df_7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41f7971",
   "metadata": {},
   "source": [
    "#### --- *PySpark* ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c333f081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+-----+--------------------+-------------------+\n",
      "|dev_key|device|  browser|count|     ratio_by_device|        ratio_total|\n",
      "+-------+------+---------+-----+--------------------+-------------------+\n",
      "|      0| 2pq93|   Chrome|    1|                 1.0|0.48032311322053495|\n",
      "|      1| 2pyb2|   Chrome|  160|   0.975609756097561|0.48032311322053495|\n",
      "|      1| 2pyb2|parse_bot|    4|0.024390243902439025|0.15272705034654813|\n",
      "|      2| 4035d|   Chrome|   39|                 1.0|0.48032311322053495|\n",
      "|      3| 5047d|   Chrome|   84|                0.84|0.48032311322053495|\n",
      "|      3| 5047d|parse_bot|   16|                0.16|0.15272705034654813|\n",
      "|      4| 5049w|   Chrome|  149|                 1.0|0.48032311322053495|\n",
      "|      5|  5050|   Chrome|   40|  0.9302325581395349|0.48032311322053495|\n",
      "|      5|  5050|parse_bot|    3| 0.06976744186046512|0.15272705034654813|\n",
      "|      6| 5050x|parse_bot|    3|                 1.0|0.15272705034654813|\n",
      "+-------+------+---------+-----+--------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# датафрейм по п.7\n",
    "\n",
    "#  первичная группировка и преобразование ps.Series к ps.DataFrame (для удобства)\n",
    "s_df_7 = (\n",
    "    df\n",
    "    .groupby(['dev_key', 'device', 'browser'])\n",
    "    .count()\n",
    "    .orderBy(f.col('dev_key').asc())\n",
    ")\n",
    "\n",
    "# дополнения (временные таблицы) для слияния с df_7 и получения расчётных величин\n",
    "s_df_7_br_by_dev = (                                               # группир-ка по устр-ву\n",
    "    s_df_7                                                         # расчёт кол-ва применений\n",
    "    .groupby(['dev_key','device'])\n",
    "    .sum('count')\n",
    "    .toDF('dev_key', 'device', 'sum')\n",
    "    .orderBy('dev_key')\n",
    ")\n",
    "\n",
    "# объединение таблиц\n",
    "s_df_7 = (\n",
    "    s_df_7\n",
    "    .join(s_df_7_br_by_dev, on=['dev_key', 'device'], how='left')\n",
    "    .orderBy(f.col('dev_key').asc())\n",
    ")\n",
    "\n",
    "# создание новой колонки со значениями\n",
    "s_df_7 = s_df_7.withColumn('ratio_by_device', f.col('count')/f.col('sum'))\n",
    "\n",
    "s_df_7_br_tot = (                                      # группир-ка по браузеру\n",
    "    df                                                 # расчёт доли от общего\n",
    "    .groupby(['browser'])\n",
    "    .count()\n",
    ")\n",
    "\n",
    "# добавление колонки с долей от общего кол-ва\n",
    "tot_count = s_df_7_br_tot.select(f.sum('count')).collect()\n",
    "\n",
    "s_df_7_br_tot = (\n",
    "    s_df_7_br_tot\n",
    "    .withColumn('ratio_total', f.col('count')/tot_count[0][0])\n",
    "    .select(['browser', 'ratio_total'])\n",
    ")\n",
    "\n",
    "# объединение таблиц\n",
    "s_df_7 = (\n",
    "    s_df_7\n",
    "    .join(s_df_7_br_tot, on=['browser'], how='left')\n",
    "    .select(['dev_key', 'device', 'browser', 'count', 'ratio_by_device', 'ratio_total'])\n",
    "    .orderBy(f.col('dev_key').asc(), f.col('count').desc())\n",
    ")\n",
    "\n",
    "s_df_7.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5c212d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Комментарий студента:</b>\n",
    "<br>\n",
    "Пока что я не нашёл более простого способа обращаться к значениям переменных в Spark кроме как по индексам (tot_count[0][0]). Такой способ явно должен существовать в виде вызова того или иного метода, но возникающие ошибки не позволили разобраться и я обратился к тому методу, который работал надёжнее.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a95f30",
   "metadata": {},
   "source": [
    "Одинаковый результат, транслируем методы и на последний пунтк задания.\n",
    "\n",
    "***\n",
    "\n",
    "###  Задания 8-9. <a class=\"anchor\" id=\"5.6\"></a>  \n",
    "\n",
    "#### --- *Pandas API* ---\n",
    "\n",
    "- Дополним витрину данными об ответах сервера: \n",
    "\n",
    "    ***8.*** *Количество ответов сервера, отличных от 200, на данном устройстве.*  \n",
    "    ***9.*** *Для каждого из ответов сервера, отличных от 200, сформировать поле, в котором будет содержаться количество ответов данного типа.*  \n",
    "    \n",
    "По-прежнему нам достаточно будет сгруппировать датафрейм по ключам 'dev_key' и 'serv_answer_1' для строк, в которых значение ответа не равно 200, а также поститать такие вхождения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "30c84820",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>not200_sum_by_device</th>\n",
       "      <th>not200_answers_qty</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev_key</th>\n",
       "      <th>device</th>\n",
       "      <th>serv_answer_1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>2pyb2</th>\n",
       "      <th>302</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>4035d</th>\n",
       "      <th>302</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>5047d</th>\n",
       "      <th>302</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">5049w</th>\n",
       "      <th>301</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>5050</th>\n",
       "      <th>302</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>5095k</th>\n",
       "      <th>302</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">9</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">6p</th>\n",
       "      <th>302</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <th>708g</th>\n",
       "      <th>302</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              not200_sum_by_device  not200_answers_qty\n",
       "dev_key device serv_answer_1                                          \n",
       "1       2pyb2  302                               2                   2\n",
       "2       4035d  302                               8                   8\n",
       "3       5047d  302                               2                   2\n",
       "4       5049w  301                               2                   1\n",
       "               302                               2                   1\n",
       "5       5050   302                               1                   1\n",
       "7       5095k  302                               1                   1\n",
       "9       6p     302                               8                   1\n",
       "               304                               8                   7\n",
       "12      708g   302                               1                   1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# датафрейм для п.8-9 без строк с отвтеом 200\n",
    "\n",
    "pds_df_8_9 = (\n",
    "    ps.DataFrame(\n",
    "        pds_df\n",
    "        .loc[pds_df.loc[:, 'serv_answer_1'] != 200, :]\n",
    "        .groupby(['dev_key', 'device', 'serv_answer_1'])\n",
    "        .count()['serv_answer_2']\n",
    "    ).rename(columns = {'serv_answer_2' : 'not200_answers_qty'})\n",
    "     .sort_index()\n",
    ")\n",
    "\n",
    "# добавляем столбец с суммарным кол-вом ответов, отличных от 200\n",
    "# метод .transform('sum') не поддерживает тот же функционал, что в pandas, надёжнее было объединить с пом. join\n",
    "sum_by_device = (\n",
    "    pds_df_8_9\n",
    "    .reset_index()\n",
    "    .groupby('dev_key')\n",
    "    .sum()\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "pds_df_8_9 = (\n",
    "    pds_df_8_9\n",
    "    .reset_index()\n",
    "    .set_index('dev_key')\n",
    "    .merge(sum_by_device, how='left', left_index=True, right_index=True)\n",
    ")\n",
    "\n",
    "# меняем порядок следования столбцов, удаляем повторяющиеся, переименовываем\n",
    "pds_df_8_9 = pds_df_8_9.drop(['serv_answer_1_y'], axis = 1)\n",
    "pds_df_8_9 = (\n",
    "    pds_df_8_9\n",
    "    .rename(columns = {'serv_answer_1_x':'serv_answer_1', 'not200_answers_qty_y':'not200_sum_by_device'\n",
    "                       , 'not200_answers_qty_x':'not200_answers_qty'})\n",
    "    .reset_index()\n",
    "    .set_index(['dev_key', 'device', 'serv_answer_1'])\n",
    "    .reindex(columns=['not200_sum_by_device', 'not200_answers_qty'])\n",
    ")\n",
    "\n",
    "pds_df_8_9.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a9090c",
   "metadata": {},
   "source": [
    "#### --- *PySpark* ---\n",
    "\n",
    "Для экономии времени в этом месте вызовем метод `.to_spark` к полученному выше датафрейму `pds_df_8_9`. Он позволит получить из `pyspark.pandas.frame.DataFrame` объект `pyspark.sql.dataframe.DataFrame` без длительных преобразований, т.е. не потребуется переисывание **Spark SQL**-методами кода, составленного на **Pandas API**. Учесть стоит необходимость указания индекса исходной таблицы для сохранения этой информации, а также использование **Spark**-actions для работы с полученным датафреймом (`.show()` и `.collect()`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b8b342c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 165:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------------+--------------------+------------------+\n",
      "|dev_key|  device|serv_answer_1|not200_sum_by_device|not200_answers_qty|\n",
      "+-------+--------+-------------+--------------------+------------------+\n",
      "|      1|   2pyb2|          302|                   2|                 2|\n",
      "|      2|   4035d|          302|                   8|                 8|\n",
      "|      3|   5047d|          302|                   2|                 2|\n",
      "|      4|   5049w|          301|                   2|                 1|\n",
      "|      4|   5049w|          302|                   2|                 1|\n",
      "|      5|    5050|          302|                   1|                 1|\n",
      "|      7|   5095k|          302|                   1|                 1|\n",
      "|      9|      6p|          302|                   8|                 1|\n",
      "|      9|      6p|          304|                   8|                 7|\n",
      "|     12|    708g|          302|                   1|                 1|\n",
      "|     17|   9002x|          302|                   1|                 1|\n",
      "|     19|   9007a|          302|                   2|                 2|\n",
      "|     20|    a 3g|          499|                   1|                 1|\n",
      "|     21|   a0001|          304|                   2|                 1|\n",
      "|     21|   a0001|          499|                   2|                 1|\n",
      "|     23|  a1-713|          302|                   2|                 1|\n",
      "|     23|  a1-713|          404|                   2|                 1|\n",
      "|     24|a1-713hd|          301|                  32|                 2|\n",
      "|     24|a1-713hd|          302|                  32|                17|\n",
      "|     24|a1-713hd|          304|                  32|                11|\n",
      "+-------+--------+-------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_df_8_9 = pds_df_8_9.to_spark(index_col=['dev_key', 'device', 'serv_answer_1'])\n",
    "s_df_8_9.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533296c7",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "По-прежнему в целях унификации можно объединить витрины по пунктам 1-6, датафреймы п.7 и п.8-9 получились разнородными, их имеет смысл рассматривать отдельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4505d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Витрина данных по п.1-6 (фрагмент)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 183:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+-----------+-----------+-----------------------+\n",
      "|dev_key|device|users_qty|users_ratio|actions_qty|actions_ratio_by_device|\n",
      "+-------+------+---------+-----------+-----------+-----------------------+\n",
      "|      0| 2pq93|        1|        0.0|          1|               7.771E-7|\n",
      "|      1| 2pyb2|        1|        0.0|        139|             1.08016E-4|\n",
      "|      2| 4035d|        2|     1.0E-5|         26|             2.02044E-5|\n",
      "|      3| 5047d|        6|     2.0E-5|         83|             6.44988E-5|\n",
      "|      4| 5049w|        1|        0.0|        137|            1.064618E-4|\n",
      "|      5|  5050|        4|     1.0E-5|         43|              3.3415E-5|\n",
      "|      6| 5050x|        1|        0.0|          3|              2.3313E-6|\n",
      "|      7| 5095k|        1|        0.0|         18|             1.39877E-5|\n",
      "|      8| 6043d|        4|     1.0E-5|         58|             4.50714E-5|\n",
      "|      9|    6p|       16|     6.0E-5|        145|            1.126786E-4|\n",
      "+-------+------+---------+-----------+-----------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# объединим витрины п.1-4 и 5-6\n",
    "s_df_1_6 = (\n",
    "    s_df_1_4\n",
    "    .join(s_df_5_6, how='left', on=['dev_key', 'device'])\n",
    "    .toDF('dev_key', 'device', 'users_qty', 'users_ratio', 'actions_qty', 'actions_ratio_by_device')\n",
    ")\n",
    "print('Витрина данных по п.1-6 (фрагмент)')\n",
    "s_df_1_6.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d3f35f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Витрина данных по п.7 (фрагмент)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+-----+--------------------+-------------------+\n",
      "|dev_key|device|  browser|count|     ratio_by_device|        ratio_total|\n",
      "+-------+------+---------+-----+--------------------+-------------------+\n",
      "|      0| 2pq93|   Chrome|    1|                 1.0|0.48032311322053495|\n",
      "|      1| 2pyb2|   Chrome|  160|   0.975609756097561|0.48032311322053495|\n",
      "|      1| 2pyb2|parse_bot|    4|0.024390243902439025|0.15272705034654813|\n",
      "|      2| 4035d|   Chrome|   39|                 1.0|0.48032311322053495|\n",
      "|      3| 5047d|   Chrome|   84|                0.84|0.48032311322053495|\n",
      "|      3| 5047d|parse_bot|   16|                0.16|0.15272705034654813|\n",
      "|      4| 5049w|   Chrome|  149|                 1.0|0.48032311322053495|\n",
      "|      5|  5050|   Chrome|   40|  0.9302325581395349|0.48032311322053495|\n",
      "|      5|  5050|parse_bot|    3| 0.06976744186046512|0.15272705034654813|\n",
      "|      6| 5050x|parse_bot|    3|                 1.0|0.15272705034654813|\n",
      "+-------+------+---------+-----+--------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Витрина данных по п.8-9 (фрагмент)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 213:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------------+--------------------+------------------+\n",
      "|dev_key|device|serv_answer_1|not200_sum_by_device|not200_answers_qty|\n",
      "+-------+------+-------------+--------------------+------------------+\n",
      "|      1| 2pyb2|          302|                   2|                 2|\n",
      "|      2| 4035d|          302|                   8|                 8|\n",
      "|      3| 5047d|          302|                   2|                 2|\n",
      "|      4| 5049w|          301|                   2|                 1|\n",
      "|      4| 5049w|          302|                   2|                 1|\n",
      "|      5|  5050|          302|                   1|                 1|\n",
      "|      7| 5095k|          302|                   1|                 1|\n",
      "|      9|    6p|          302|                   8|                 1|\n",
      "|      9|    6p|          304|                   8|                 7|\n",
      "|     12|  708g|          302|                   1|                 1|\n",
      "+-------+------+-------------+--------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# отобразим витрину по п.7\n",
    "print('Витрина данных по п.7 (фрагмент)')\n",
    "s_df_7.show(10)\n",
    "\n",
    "# отобразим витрину по п.8-9\n",
    "print('Витрина данных по п.8-9 (фрагмент)')\n",
    "s_df_8_9.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e512f4",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Вывод.\n",
    "\n",
    "\n",
    "Витрины данных получены различными способами, но, будучи построенными разными инструментами, все показывают одинаковую информацию.\n",
    "\n",
    "Для дальнейшей работы лишь остановимся на витринах вида `pyspark.sql.dataframe.DataFrame`, поскольку **Pandas API** пока просто не имеет такого многообразия методов ввода-вывода для `pyspark.pandas.frame.DataFrame`, как **Spark SQL**. Например в части выгрузки витрин в SQL-Базы Данных. (Хотя имеющиеся методы pandas API вполне обширны и достаточны, получаемые файлы можно \"подключать\" к используемому ПО уже с помощью \"внешних\" операторов.)\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "## 6. Load.   <a class=\"anchor\" id=\"6\"></a>  \n",
    "\n",
    "Результат всех способов преобразования получается одинаковый, в этом смысле разницы, какой из них выбирать - нет. Попробуем на данном спектре вариантов решения разобраться с трансляцией полученного результата в базы данных, а также с записью и хранением в Hive и HDFS.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Комментарий:</b>\n",
    "<br>\n",
    "<br>\n",
    "В разделах ниже видно, что эта часть работы вышла \"кривой\" и нуждается в улучшениях, т.к. на сервере, где выполнялась работа, некоторые этапы реализовать не удалось. Написаный раздел работы удалять при этом рука не поднималась и он сохранился для наглядности. \n",
    "    \n",
    "Смысл действий был довольно простым: \n",
    "- получив ответы на поставленные вопросы в виде вороха разнообразных датафреймов, мне хотелось попробовать не\n",
    "  только их локальное хранение, но и транслировать результаты из Spark в БД напрямую,\n",
    "- посмотреть, как меняется скорость обработки при записи/чтении из HDFS.\n",
    "</div>\n",
    "\n",
    "\n",
    "### Работа с базами данных.   <a class=\"anchor\" id=\"6.1\"></a>  \n",
    "\n",
    "* **чтение из PostgreSQL**\n",
    "\n",
    "    Чтение из базы данных с помощью **Spark** представляется простым, т.к. в метод `.read` передается минимум параметров (безопасность подключения и использования той или БД в данной работе не рассматривается), попробуем применить параметры подключения, выданные пользователям платформы 1Т перед началом работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "82082288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql: /usr/lib/postgresql /usr/share/postgresql\r\n"
     ]
    }
   ],
   "source": [
    "# поищем, где могут лежать драйвера к postgreSQL\n",
    "!whereis postgresql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b381d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "environ{'SHELL': '/bin/bash',\n",
       "        'JUPYTERHUB_API_TOKEN': '7531fa1f416340898a0991f549afb233',\n",
       "        'JUPYTERHUB_BASE_URL': '/',\n",
       "        'PWD': '/home/jupyter-morozov_evgeny',\n",
       "        'LOGNAME': 'jupyter-morozov_evgeny',\n",
       "        'JUPYTERHUB_SERVER_NAME': '',\n",
       "        'HOME': '/home/jupyter-morozov_evgeny',\n",
       "        'LANG': 'en_US.UTF-8',\n",
       "        'JPY_API_TOKEN': '7531fa1f416340898a0991f549afb233',\n",
       "        'JUPYTERHUB_SERVICE_PREFIX': '/user/morozov_evgeny/',\n",
       "        'JUPYTERHUB_OAUTH_CALLBACK_URL': '/user/morozov_evgeny/oauth_callback',\n",
       "        'INVOCATION_ID': '838b26b4092342d5a6e19ca3d5f221ee',\n",
       "        'RUNTIME_DIRECTORY': '/run/jupyter-morozov_evgeny',\n",
       "        'USER': 'jupyter-morozov_evgeny',\n",
       "        'SHLVL': '0',\n",
       "        'JUPYTERHUB_API_URL': 'http://127.0.0.1:15001/hub/api',\n",
       "        'JUPYTERHUB_CLIENT_ID': 'jupyterhub-user-morozov_evgeny',\n",
       "        'JUPYTERHUB_HOST': '',\n",
       "        'JOURNAL_STREAM': '9:257035900',\n",
       "        'PATH': '/opt/tljh/user/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin',\n",
       "        'JUPYTERHUB_USER': 'morozov_evgeny',\n",
       "        'JUPYTERHUB_ACTIVITY_URL': 'http://127.0.0.1:15001/hub/api/users/morozov_evgeny/activity',\n",
       "        'OLDPWD': '/',\n",
       "        'JPY_PARENT_PID': '3357951',\n",
       "        'TERM': 'xterm-color',\n",
       "        'CLICOLOR': '1',\n",
       "        'FORCE_COLOR': '1',\n",
       "        'CLICOLOR_FORCE': '1',\n",
       "        'PAGER': 'cat',\n",
       "        'GIT_PAGER': 'cat',\n",
       "        'MPLBACKEND': 'module://matplotlib_inline.backend_inline',\n",
       "        'PYARROW_IGNORE_TIMEZONE': '1',\n",
       "        'SPARK_AUTH_SOCKET_TIMEOUT': '15',\n",
       "        'SPARK_BUFFER_SIZE': '65536'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# настройка для работы с PostgrSQL\n",
    "import os\n",
    "os.environ\n",
    "\n",
    "# какие-то пути из интернета, но всё-равно не известно, где в конечном итоге находятся драйверы\n",
    "#os.environ['PYSPARK_SUBMIT_ARGS'] = '''--driver-class-path /usr/lib/postgresql/12/bin\n",
    "#--jars /usr/lib/postgresql/12/bin pyspark-shell'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0062926",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "~~~python\n",
    "# последовательность вызовов на чтение из БД\n",
    "(\n",
    "    spark\n",
    "    .read\n",
    "    .format('jdbc')\n",
    "    .option('url', 'jdbc:postgresql://146.120.224.166:5432/morozov_evgeny_db')\n",
    "    .option('dbtable', 'db')\n",
    "    .option('user', 'morozov_evgeny')\n",
    "    .option('password', 'w*******')\n",
    "    .load()\n",
    ")\n",
    "~~~\n",
    "\n",
    "Код в работоспособное состояние привести не удалось, последовательность выше (как впрочем и ниже при попытке записи в БД) приводила к ошибкам.\n",
    "\n",
    "***Выдаваемый код ошибки:***\n",
    "\n",
    "~~~python\n",
    "---------------------------------------------------------------------------\n",
    "Py4JJavaError                             Traceback (most recent call last)\n",
    "Cell In[33], line 3\n",
    "      1 # последовательность вызовов на чтение из ДБ\n",
    "      2 (\n",
    "----> 3     spark\n",
    "      4     .read\n",
    "      5     .format('jdbc')\n",
    "      6     .option('url', 'jdbc:postgresql://146.120.224.166:5432/morozov_evgeny_db')\n",
    "      7     .option('dbtable', 'db')\n",
    "      8     .option('user', 'morozov_evgeny')\n",
    "      9     .option('password', 'w*******')\n",
    "     10     .load()\n",
    "     11 )\n",
    "\n",
    "File /opt/tljh/user/lib/python3.9/site-packages/pyspark/sql/readwriter.py:184, in DataFrameReader.load(self, path, format, schema, **options)\n",
    "    182     return self._df(self._jreader.load(self._spark._sc._jvm.PythonUtils.toSeq(path)))\n",
    "    183 else:\n",
    "--> 184     return self._df(self._jreader.load())\n",
    "\n",
    "File /opt/tljh/user/lib/python3.9/site-packages/py4j/java_gateway.py:1321, in JavaMember.__call__(self, *args)\n",
    "   1315 command = proto.CALL_COMMAND_NAME +\\\n",
    "   1316     self.command_header +\\\n",
    "   1317     args_command +\\\n",
    "   1318     proto.END_COMMAND_PART\n",
    "   1320 answer = self.gateway_client.send_command(command)\n",
    "-> 1321 return_value = get_return_value(\n",
    "   1322     answer, self.gateway_client, self.target_id, self.name)\n",
    "   1324 for temp_arg in temp_args:\n",
    "   1325     temp_arg._detach()\n",
    "\n",
    "File /opt/tljh/user/lib/python3.9/site-packages/pyspark/sql/utils.py:190, in capture_sql_exception.<locals>.deco(*a, **kw)\n",
    "    188 def deco(*a: Any, **kw: Any) -> Any:\n",
    "    189     try:\n",
    "--> 190         return f(*a, **kw)\n",
    "    191     except Py4JJavaError as e:\n",
    "    192         converted = convert_exception(e.java_exception)\n",
    "\n",
    "File /opt/tljh/user/lib/python3.9/site-packages/py4j/protocol.py:326, in get_return_value(answer, gateway_client, target_id, name)\n",
    "    324 value = OUTPUT_CONVERTER[type](answer[2:], gateway_client)\n",
    "    325 if answer[1] == REFERENCE_TYPE:\n",
    "--> 326     raise Py4JJavaError(\n",
    "    327         \"An error occurred while calling {0}{1}{2}.\\n\".\n",
    "    328         format(target_id, \".\", name), value)\n",
    "    329 else:\n",
    "    330     raise Py4JError(\n",
    "    331         \"An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n\".\n",
    "    332         format(target_id, \".\", name, value))\n",
    "\n",
    "Py4JJavaError: An error occurred while calling o2423.load.\n",
    ": java.sql.SQLException: No suitable driver\n",
    "\tat java.sql.DriverManager.getDriver(DriverManager.java:315)\n",
    "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:107)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93409f0d",
   "metadata": {},
   "source": [
    "* **запись в PostgreSQL**\n",
    "\n",
    "    Запись в базу данных с помощью **Spark** также не представляется сложной, в метод `.write` передаются соотв. аргументы для подключения и записи, нужно только учитывать, что метод `.write.format('jdbc')...` у датафреймов pandas API отсутствует и существует только для датафреймов `pyspark.sql.dataframe.DataFrame`.\n",
    "\n",
    "В данной работе чтение и запись в итоге произведены не были, поскольку на сервере либо не были установлены драйверов БД, либо их местоположение осталось мне неизвестно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090f54d9",
   "metadata": {},
   "source": [
    "~~~python\n",
    "#  последовательность вызовов для записи в ДБ\n",
    "(\n",
    "    s_df_1_6\n",
    "    #.repartition(3)   # просто для напомнинаия о партиционировании при записи в HDFS (к БД не имеет отношения)\n",
    "    .write\n",
    "    .format('jdbc')\n",
    "    .mode('overwrite')\n",
    "    .option('url', 'jdbc:postgresql://localhost:5432/morozov_evgeny_db')\n",
    "    #.option('url', 'jdbc:postgresql://146.120.224.166:5432/morozov_evgeny_db')\n",
    "    .option('dbtable', 'case_1_6')\n",
    "    .option('user', 'morozov_evgeny')\n",
    "    .option('password', 'w*******')\n",
    "    .save()\n",
    ")\n",
    "~~~\n",
    "\n",
    "***Выдаваемый код ошибки:***\n",
    "\n",
    "~~~python\n",
    "---------------------------------------------------------------------------\n",
    "Py4JJavaError                             Traceback (most recent call last)\n",
    "Cell In[34], line 3\n",
    "      1 #  последовательность вызовов для записи в ДБ\n",
    "      2 (\n",
    "----> 3     s_df_1_6\n",
    "      4     #.repartition(3)   # просто для напомнинаия о партиционировании при записи в HDFS (к БД не имеет отношения)\n",
    "      5     .write\n",
    "      6     .format('jdbc')\n",
    "      7     .mode('overwrite')\n",
    "      8     .option('url', 'jdbc:postgresql://localhost:5432/morozov_evgeny_db')\n",
    "      9     #.option('url', 'jdbc:postgresql://146.120.224.166:5432/morozov_evgeny_db')\n",
    "     10     .option('dbtable', 'case_1_6')\n",
    "     11     .option('user', 'morozov_evgeny')\n",
    "     12     .option('password', 'w*******')\n",
    "     13     .save()\n",
    "     14 )\n",
    "\n",
    "File /opt/tljh/user/lib/python3.9/site-packages/pyspark/sql/readwriter.py:966, in DataFrameWriter.save(self, path, format, mode, partitionBy, **options)\n",
    "    964     self.format(format)\n",
    "    965 if path is None:\n",
    "--> 966     self._jwrite.save()\n",
    "    967 else:\n",
    "    968     self._jwrite.save(path)\n",
    "\n",
    "File /opt/tljh/user/lib/python3.9/site-packages/py4j/java_gateway.py:1321, in JavaMember.__call__(self, *args)\n",
    "   1315 command = proto.CALL_COMMAND_NAME +\\\n",
    "   1316     self.command_header +\\\n",
    "   1317     args_command +\\\n",
    "   1318     proto.END_COMMAND_PART\n",
    "   1320 answer = self.gateway_client.send_command(command)\n",
    "-> 1321 return_value = get_return_value(\n",
    "   1322     answer, self.gateway_client, self.target_id, self.name)\n",
    "   1324 for temp_arg in temp_args:\n",
    "   1325     temp_arg._detach()\n",
    "\n",
    "File /opt/tljh/user/lib/python3.9/site-packages/pyspark/sql/utils.py:190, in capture_sql_exception.<locals>.deco(*a, **kw)\n",
    "    188 def deco(*a: Any, **kw: Any) -> Any:\n",
    "    189     try:\n",
    "--> 190         return f(*a, **kw)\n",
    "    191     except Py4JJavaError as e:\n",
    "    192         converted = convert_exception(e.java_exception)\n",
    "\n",
    "File /opt/tljh/user/lib/python3.9/site-packages/py4j/protocol.py:326, in get_return_value(answer, gateway_client, target_id, name)\n",
    "    324 value = OUTPUT_CONVERTER[type](answer[2:], gateway_client)\n",
    "    325 if answer[1] == REFERENCE_TYPE:\n",
    "--> 326     raise Py4JJavaError(\n",
    "    327         \"An error occurred while calling {0}{1}{2}.\\n\".\n",
    "    328         format(target_id, \".\", name), value)\n",
    "    329 else:\n",
    "    330     raise Py4JError(\n",
    "    331         \"An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n\".\n",
    "    332         format(target_id, \".\", name, value))\n",
    "\n",
    "Py4JJavaError: An error occurred while calling o2431.save.\n",
    ": java.sql.SQLException: No suitable driver\n",
    "\tat java.sql.DriverManager.getDriver(DriverManager.java:315)\n",
    "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:107)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166e4acb",
   "metadata": {},
   "source": [
    "* **запись и чтение в реляционное хранилище Hive** \n",
    "\n",
    "    Запись в БД **Hive** не требует установки драйверов и похожа на запись в простой файл, с той разницей, что вместо метода `.save()` вызывается метод `.saveAsTable()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b313eccc",
   "metadata": {},
   "source": [
    "~~~python\n",
    "# команды отрабатывали только с методом .save() на конце, но файл \"улетал\" в неизвестном направлении, видимо.\n",
    "# в HUE найден не был, сам HUE тоже был доступен не каждый раз. Поэтому последовательность команд перенес в \n",
    "# markdown-ячейку.\n",
    "(\n",
    "    s_df_1_4\n",
    "    .repartition(3)   # партиционирование при записи в HDFS\n",
    "    .write\n",
    "    .format('orc')\n",
    "    #.partitionBy('device')\n",
    "    .mode('overwrite')\n",
    "    #.option('compression','gzip')\n",
    "    .save('hdfs://localhost:9099/user/morozov_evgeny/')\n",
    ")\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c5a4b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: hadoop: command not found\r\n"
     ]
    }
   ],
   "source": [
    "! hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "93cb4e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: hdfs: command not found\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls -R hdfs://localhost:9099/user/morozov_evgeny/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31651270",
   "metadata": {},
   "source": [
    "Изначально казалось, что в данной сессии есть возможность писать в HDFS, но по всей видимости работа в 'local'-режиме не предусматривает такой возможности... \n",
    "\n",
    "*Отрицательный опыт - тоже опыт, удалять эту часть работы не станем, поскольку есть определённый потенциал к её решению и он может быть развит.  Поскольку начинания успехом не увенчались, то используем метод, зарекомендовавший себя как более отлаженный.*  \n",
    "\n",
    "***\n",
    "\n",
    "* **запись в metastore HIVE**\n",
    "\n",
    "Ещё ранее (при обращении к данным посредством SQL-запросов и регистрации временных таблиц) в папке с запущенным проектом **Spark** создал директорию `./spark-warehouse` для хранения метаданных таблиц, в ней же Hive будет по умолчанию хранить созданные таблицы.  \n",
    "\n",
    "Запишем получившиеся витрины и продублируем итоги в папку **\"output_data\"**, поскольку способы выше не дали желаемых результатов, такой способ также можно считать завершением этапа **LOAD** и выполнением работы.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d22be02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#  вручную пропишем последовательность вызовов для записи в Hive\n",
    "(\n",
    "    s_df_1_6\n",
    "    .repartition(3)   # оставил для напомнинаия о партиционировании при записи\n",
    "    .write\n",
    "    .format('parquet')\n",
    "    #.partitionBy('device')\n",
    "    .mode('overwrite')\n",
    "    #.option('compression','gzip')\n",
    "    .saveAsTable('case_1_6_parquet')\n",
    ")\n",
    "(\n",
    "    s_df_7\n",
    "    .repartition(3)\n",
    "    .write\n",
    "    .format('parquet')\n",
    "    #.partitionBy('device')\n",
    "    .mode('overwrite')\n",
    "    #.option('compression','gzip')\n",
    "    .saveAsTable('case_7_parquet')\n",
    ")\n",
    "(\n",
    "    s_df_8_9\n",
    "    .repartition(3)\n",
    "    .write\n",
    "    .format('parquet')\n",
    "    #.partitionBy('device')\n",
    "    .mode('overwrite')\n",
    "    #.option('compression','gzip')\n",
    "    .saveAsTable('case_8_9_parquet')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850d3191",
   "metadata": {},
   "source": [
    "Заглянем в директорию spark-warehouse, там можно найти созданные папки вида `case_*_parquet` с партиционированными файлами витрин и файлом-флагом _SUCCESS, которые говорят об успешности записи бинарных файлов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "254e3fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12K\r\n",
      "drwxr-xr-x 2 jupyter-morozov_evgeny jupyter-morozov_evgeny 4.0K Jan  9 00:46 case_1_6_parquet\r\n",
      "drwxr-xr-x 2 jupyter-morozov_evgeny jupyter-morozov_evgeny 4.0K Jan  9 00:46 case_7_parquet\r\n",
      "drwxr-xr-x 2 jupyter-morozov_evgeny jupyter-morozov_evgeny 4.0K Jan  9 00:46 case_8_9_parquet\r\n"
     ]
    }
   ],
   "source": [
    "! ls -lh spark-warehouse/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a1db752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 92K\r\n",
      "-rw-r--r-- 1 jupyter-morozov_evgeny jupyter-morozov_evgeny 29K Jan  9 00:46 part-00000-7da88f6d-c1b3-4c13-98eb-97b2f754c66f-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 jupyter-morozov_evgeny jupyter-morozov_evgeny 29K Jan  9 00:46 part-00001-7da88f6d-c1b3-4c13-98eb-97b2f754c66f-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 jupyter-morozov_evgeny jupyter-morozov_evgeny 28K Jan  9 00:46 part-00002-7da88f6d-c1b3-4c13-98eb-97b2f754c66f-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 jupyter-morozov_evgeny jupyter-morozov_evgeny   0 Jan  9 00:46 _SUCCESS\r\n"
     ]
    }
   ],
   "source": [
    "! ls -lh spark-warehouse/case_1_6_parquet/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acd8b04",
   "metadata": {},
   "source": [
    "Для открытия файла можно использовать более быстрый (чем `.read.format().option().load()`) метод `spark.sql()` с соотв. запросом к указанной таблице, т.к. по всей видимости **Spark** настроен на работу c хранилищем Hive и обращается именно к нему. Обратимся к методу с использованием команд HiveQL и проверим готовность витрин."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc44358c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+-----------+\n",
      "|namespace|       tableName|isTemporary|\n",
      "+---------+----------------+-----------+\n",
      "|  default|case_1_6_parquet|      false|\n",
      "|  default|  case_7_parquet|      false|\n",
      "|  default|case_8_9_parquet|      false|\n",
      "|         |             1_4|       true|\n",
      "+---------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# в языке Hive_QL есть команды для отображения таблиц БД \n",
    "spark.sql('show tables').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7624782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+---------+-----------+-----------+-----------------------+\n",
      "|dev_key|              device|users_qty|users_ratio|actions_qty|actions_ratio_by_device|\n",
      "+-------+--------------------+---------+-----------+-----------+-----------------------+\n",
      "|   2181|               s4700|       24|     9.0E-5|        153|            1.188953E-4|\n",
      "|   3113|           sph-l720t|        2|     1.0E-5|         69|             5.36195E-5|\n",
      "|   1887|               pc704|        2|     1.0E-5|         24|             1.86503E-5|\n",
      "|   3249|             vsun h3|        1|        0.0|         83|             6.44988E-5|\n",
      "|   3188|             trt-lx1|        1|        0.0|          1|               7.771E-7|\n",
      "|   2074|redmi note 4 miui...|        1|        0.0|          5|              3.8855E-6|\n",
      "|   2583|              selfie|       19|     7.0E-5|         93|             7.22697E-5|\n",
      "|    560|            gt-s5670|        4|     1.0E-5|         13|             1.01022E-5|\n",
      "|   2221|    samsung gt-s7270|        1|        0.0|         12|              9.3251E-6|\n",
      "|   2999|           sm-t116nu|        8|     3.0E-5|        148|            1.150099E-4|\n",
      "+-------+--------------------+---------+-----------+-----------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- dev_key: long (nullable = true)\n",
      " |-- device: string (nullable = true)\n",
      " |-- users_qty: long (nullable = true)\n",
      " |-- users_ratio: double (nullable = true)\n",
      " |-- actions_qty: long (nullable = true)\n",
      " |-- actions_ratio_by_device: double (nullable = true)\n",
      "\n",
      "Количество строк case_1_6_parquet = 3381\n"
     ]
    }
   ],
   "source": [
    "# обратимся к Hive для загрузки\n",
    "hivedf = spark.sql('SELECT * FROM case_1_6_parquet')\n",
    "hivedf.show(10)\n",
    "hivedf.printSchema()\n",
    "print('Количество строк case_1_6_parquet =', hivedf.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70826c2",
   "metadata": {},
   "source": [
    "Информация из партиционированной таблицы считана верно, размеры исходной и загруженной таблиц совпадают. Результат перед завершением скопируем в соотв. папку для хранения.\n",
    "\n",
    "## 7. Вывод.   <a class=\"anchor\" id=\"7\"></a>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68d05a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Работа завершена, останавливаем сессию.\n"
     ]
    }
   ],
   "source": [
    "# в качестве иллюстрации\n",
    "print('Работа завершена, останавливаем сессию.')\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49aefb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Полученные витрины данных и датафрейм с распарсенными логами в директории \u001b[1moutput_data\u001b[0m:\n",
      "total 112M\n",
      "drwxr-xr-x 2 jupyter-morozov_evgeny jupyter-morozov_evgeny 4.0K Jan  8 01:42 case_1_6_parquet\n",
      "drwxr-xr-x 2 jupyter-morozov_evgeny jupyter-morozov_evgeny 4.0K Jan  8 01:42 case_7_parquet\n",
      "drwxr-xr-x 2 jupyter-morozov_evgeny jupyter-morozov_evgeny 4.0K Jan  8 01:42 case_8_9_parquet\n",
      "-rw-r--r-- 1 jupyter-morozov_evgeny jupyter-morozov_evgeny 112M Jan  9 00:42 parsed_logs_df.parquet\n"
     ]
    }
   ],
   "source": [
    "print('Полученные витрины данных и датафрейм с распарсенными логами в директории',\n",
    "      '\\033[1m' + 'output_data' + '\\033[0m:')\n",
    "! ls -lh ./output_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce17d6b6",
   "metadata": {},
   "source": [
    "Как говорилось выше: витрины данных получены различными способами, но, будучи построенными разными инструментами, все показывают одинаковую информацию. \n",
    "\n",
    "- Была предпринята попытка реализации логики обработки данных, условно принятых за \"большие\", последовательное формулирование целей работы и подбор инструментов для их реализаци заняли значительное время, но результат всё-таки был получен.  \n",
    "\n",
    "\n",
    "- Таким образом была отработана возможность переноса методов **Pandas** в мир **Spark** и сделано их сопоставление как представителей разных \"парадигм\" вычислений: мира последовательных (хоть и в немалой степени оптимизированных) вычислений и распределенных/отложеных вычислений.Проведено натурное исследование взаимодействия программных платформ для обработки \"больших данных\".  \n",
    "\n",
    "\n",
    "- В настоящее время, с включением **Pandas API** в состав low-level API **Spark**, количество способов обработки только возросло, но взаимодействие между библиотеками оказалось удивиельно \"гибким\" и \"прозрачным\". На скорости исполнения кода такие нововведения практически не сказываются, на мой взгляд, т.к. все оболочки (от Scala-shell и Python-shell до API SQL и API Pandas) в конечном счёте вызывают одни и теже методы движка **Spark** для работы с **RDD**, предварительно подвергаясь оптимизациям, что должно практически уравнивать методы.  \n",
    "\n",
    "\n",
    "- Что касается хода выполнения работы: \n",
    "\n",
    "    - предварительное решение и приёмы работы c данными такого объёма отрабатывались в библиотеке **Pandas** и **Python** на сокращённых выборках, затем оптимизировались для сокращения потребления памяти (в меру понимания процесса и в учебных целях) и таким образом, хоть и не с первого раза, но всё же с помощью выделенного сервера удалось обработать файл логов целиком без разделения и последовательной обработки батчей. \n",
    "    - Затем решения воспроизводилось уже на платформе для работы с \"большими данными\", в качестве таковой был выбран фреймворк **Apache Spark**, показавший себя мощным и универсальным инструментом. \n",
    "    - Сравнение или обработка данных с помощью \"НЕкластерных\" фреймворков\\библиотек вроде **Dask** или **Polars** не производилось (что, может быть интересно в последствии, т.к. они занимают некую промежуточную нишу между выбранными выше инструментами).  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
